[
  {
    "objectID": "06_localization.html#robotics-and-automated-systems",
    "href": "06_localization.html#robotics-and-automated-systems",
    "title": "06_localization",
    "section": "Robotics and Automated Systems",
    "text": "Robotics and Automated Systems\n\n\nLocalization\n\n\n\nInstructor: Aykut Satici, Ph.D.¬†\n¬†\n\nMechanical and Biomedical Engineering \nElectrical and Computer Engineering \nBoise State University, Boise, ID, USA\n\n\nTopics: \n\nDead Reckoning\nLocalizing with a Map\nCreating a Map\nLocalization and Mapping\nPose Graph SLAM\nComplementary filter"
  },
  {
    "objectID": "06_localization.html#localization-1",
    "href": "06_localization.html#localization-1",
    "title": "06_localization",
    "section": "Localization",
    "text": "Localization\n\n\n\nGPS makes outdoor localization easy; unfortunately GPS is far from perfect.\n\nrelies on very weak radio signals received from distant orbiting satellites.\nGPS cannot work where there is no line of sight radio reception.\n\nGPS has only been in use since 1995 yet humankind has been navigating the planet and localizing for many thousands of years!\nDead reckoning is the estimation of location based on estimated speed, direction and time of travel w.r.t. a previous estimate.\n\n\n\n\n\n\n\nGiven average compass heading over the previous hour and a distance traveled the position at 33 p.m. can be found using elementary geometry from the position at 22 p.m.\n\nMeasurements on which the update is based are subject to both systematic and random error.\nModern instruments are quite precise but 500 years ago clocks, compasses and speed measurements were primitive."
  },
  {
    "objectID": "06_localization.html#localization-2",
    "href": "06_localization.html#localization-2",
    "title": "06_localization",
    "section": "Localization",
    "text": "Localization\n\n\n\nEstimates are recursive: each estimate is based on the previous one.\n\nerrors will accumulate over time\nfor sea voyages of many-years this approach was quite inadequate!\n\nThe Phonecians were navigating at sea more than 4,0004,000 years ago and they did not even have a compass!\n\n\n\n\n\n\n\nThey navigated with crude dead reckoning but wherever possible they used additional information to correct their position estimate.\n\nsightings of islands and headlands\nprimitive maps and observations of the Sun and the Pole Star."
  },
  {
    "objectID": "06_localization.html#localization-3",
    "href": "06_localization.html#localization-3",
    "title": "06_localization",
    "section": "Localization",
    "text": "Localization\n\nA landmark is a visible feature in the environment whose location is known w.r.t. some coordinate frame.\n\nA precise bearing measurement to two landmarks will therefore pinpoint our location, a process known as resectioning.\n\n\n\n\n\nThis process is critically reliant on correctly associating the observed landmark with the feature on the map.\n\nMistaking one lighthouse for another, e.g.¬†ùêÇ\\bm{C} for ùêÅ\\bm{B} leads to significant error in estimated position (ùê™\\bm{q} instead of ùê©\\bm{p}).\n\nThis is a very common error and countless ships have foundered because of this fundamental data association error.\n\nThis is why lighthouses flash with a unique flashing pattern!"
  },
  {
    "objectID": "06_localization.html#localization-4",
    "href": "06_localization.html#localization-4",
    "title": "06_localization",
    "section": "Localization",
    "text": "Localization\n¬†\n\n\n\n\n\nLocalization Problem\n\n\nFind an estimate ùê±ÃÇ\\hat{\\bm{x}} of the true, but unknown position, ùê±\\bm{x} of the robot. We also wish to know the uncertainty of the estimate (standard deviation associated with the position estimate ùê±ÃÇ\\hat{\\bm{x}}).\n\n\n\n\nIt is useful to describe a robot‚Äôs estimated position in terms of a probability density function over all possible positions of the robot.\n\nallows for multiple hypotheses about the robot‚Äôs position."
  },
  {
    "objectID": "06_localization.html#dead-reckoning-1",
    "href": "06_localization.html#dead-reckoning-1",
    "title": "06_localization",
    "section": "Dead reckoning",
    "text": "Dead reckoning\n\nAn odometer is a sensor that measures distance traveled and sometimes also change in heading direction.\n\nFor wheeled devices, can be determined by measuring the angular rotation of the wheels.\nDirection of travel can be measured using a compass or\nChange in heading can be measured using a gyroscope.\n\nThese sensors are imperfect due to systematic errors\n\nincorrect wheel radius,\ngyroscope bias\n\nThey are also imperfect due to random errors such as slip between wheels and the ground.\nRobots w/o wheels, such as aerial and underwater robots, can use visual odometry based on observations of the world moving past the robot."
  },
  {
    "objectID": "06_localization.html#modeling-the-vehicle",
    "href": "06_localization.html#modeling-the-vehicle",
    "title": "06_localization",
    "section": "Modeling the vehicle",
    "text": "Modeling the vehicle\n\nThe first step in estimating the robot‚Äôs pose is to write a function, ùêü(‚ãÖ)\\bm{f}(\\cdot), that describes how the vehicle‚Äôs configuration changes from one time step to the next.\nThe initial pose is represented in ùêíùêÑ(2)\\bm{SE}(2) as Œæ‚ü®k‚ü©‚àº(cosŒ∏‚ü®k‚ü©‚àísinŒ∏‚ü®k‚ü©x‚ü®k‚ü©sinŒ∏‚ü®k‚ü©cosŒ∏‚ü®k‚ü©y‚ü®k‚ü©001)\n\\xi\\langle k \\rangle \\sim\n\\begin{pmatrix}\n\\cos{\\theta\\langle k \\rangle} & -\\sin{\\theta\\langle k \\rangle} & x\\langle k\n\\rangle \\\\ \n\\sin{\\theta\\langle k \\rangle} & \\cos{\\theta\\langle k \\rangle} & y\\langle k\n\\rangle \\\\ \n0 & 0 & 1\n\\end{pmatrix}\n\nMove forward in the vehicle xx-direction by Œ¥d\\delta_d and then rotate by Œ¥Œ∏\\delta_\\theta giving the new configuration Œæ‚ü®k‚ü©‚àº(cosŒ∏‚ü®k‚ü©‚àísinŒ∏‚ü®k‚ü©x‚ü®k‚ü©sinŒ∏‚ü®k‚ü©cosŒ∏‚ü®k‚ü©y‚ü®k‚ü©001)(10Œ¥d010001)(cosŒ¥Œ∏‚àísinŒ¥Œ∏0sinŒ¥Œ∏cosŒ¥Œ∏0001)‚àº(cos(Œ∏‚ü®k‚ü©+Œ¥Œ∏)‚àísin(Œ∏‚ü®k‚ü©+Œ¥Œ∏)x‚ü®k‚ü©+Œ¥dcosŒ∏‚ü®k‚ü©sin(Œ∏‚ü®k‚ü©+Œ¥Œ∏)cos(Œ∏‚ü®k‚ü©+Œ¥Œ∏)y‚ü®k‚ü©+Œ¥dsinŒ∏‚ü®k‚ü©001)\n\\begin{aligned}\n\\xi\\langle k \\rangle &\\sim\n\\begin{pmatrix}\n\\cos{\\theta\\langle k \\rangle} & -\\sin{\\theta\\langle k \\rangle} & x\\langle k\n\\rangle \\\\ \n\\sin{\\theta\\langle k \\rangle} & \\cos{\\theta\\langle k \\rangle} & y\\langle k\n\\rangle \\\\ \n0 & 0 & 1\n\\end{pmatrix}\n\\begin{pmatrix}\n1 & 0 & \\delta_d \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1\n\\end{pmatrix}\n\\begin{pmatrix}\n\\cos{\\delta_\\theta} & -\\sin{\\delta_\\theta} & 0 \\\\\n\\sin{\\delta_\\theta} & \\cos{\\delta_\\theta} & 0 \\\\ \n0 & 0 & 1\n\\end{pmatrix} \\\\ \n&\\sim\n\\begin{pmatrix}\n\\cos{\\left(\\theta \\langle k \\rangle + \\delta_\\theta\\right)} &\n-\\sin{\\left(\\theta\\langle k \\rangle + \\delta_\\theta\\right)} & \nx\\langle k \\rangle + \\delta_d \\cos{\\theta\\langle k \\rangle} \\\\\n\\sin{\\left(\\theta \\langle k \\rangle + \\delta_\\theta\\right)} &\n\\cos{\\left(\\theta\\langle k \\rangle + \\delta_\\theta\\right)} & \ny\\langle k \\rangle + \\delta_d \\sin{\\theta\\langle k \\rangle} \\\\\n0 & 0 & 1\n\\end{pmatrix}\n\\end{aligned}"
  },
  {
    "objectID": "06_localization.html#modeling-the-vehicle-1",
    "href": "06_localization.html#modeling-the-vehicle-1",
    "title": "06_localization",
    "section": "Modeling the vehicle",
    "text": "Modeling the vehicle\n\nLet‚Äôs represent this succinctly as a 33-vector ùê±=(x,y,Œ∏)\\bm{x} = (x, y, \\theta) so that ùê±‚ü®k+1‚ü©=(x‚ü®k‚ü©+Œ¥dcosŒ∏‚ü®k‚ü©y‚ü®k‚ü©+Œ¥dsinŒ∏‚ü®k‚ü©Œ∏‚ü®k‚ü©+Œ¥Œ∏)\n\\bm{x}\\langle k+1 \\rangle = \\begin{pmatrix}\nx\\langle k \\rangle + \\delta_d \\cos{\\theta\\langle k \\rangle} \\\\\ny\\langle k \\rangle + \\delta_d \\sin{\\theta\\langle k \\rangle} \\\\\n\\theta\\langle k \\rangle + \\delta_\\theta\n\\end{pmatrix}\n which gives the new configuration in terms of the previous configuration and the odometry.\nOdometry is not perfect and we model the error by imagining a random number generator (vd,vŒ∏)(v_d, v_\\theta) that corrupts the output of a perfect odometer (sensor noise).\n\n\n\n\nRobot‚Äôs configuration at the next time step, including odometry error\n\n\nùê±‚ü®k+1‚ü©=ùêü(ùê±‚ü®k‚ü©,Œ¥‚ü®k‚ü©,ùêØ‚ü®k‚ü©)=(x‚ü®k‚ü©+(Œ¥d+vd)cosŒ∏‚ü®k‚ü©y‚ü®k‚ü©+(Œ¥d+vd)sinŒ∏‚ü®k‚ü©Œ∏‚ü®k‚ü©+Œ¥Œ∏+vŒ∏)\n\\bm{x}\\langle k+1 \\rangle = \\bm{f}\\left( \\bm{x}\\langle k \\rangle, \\delta \\langle\nk \\rangle, \\bm{v}\\langle k \\rangle \\right) = \\begin{pmatrix}\nx\\langle k \\rangle + (\\delta_d+v_d) \\cos{\\theta\\langle k \\rangle} \\\\\ny\\langle k \\rangle + (\\delta_d+v_d) \\sin{\\theta\\langle k \\rangle} \\\\\n\\theta\\langle k \\rangle + \\delta_\\theta + v_\\theta\n\\end{pmatrix}\n\n\n\n\n\nWe typically model the odometry noise as ùêØ=(vd,vŒ∏)‚ä§‚àºùí©(0,ùêï)\\bm{v} = \\left(v_d,\nv_\\theta\\right)^\\top \\sim \\mathcal{N}(0, \\bm{V}), a zero-mean multivariate Gaussian, with variance ùêï=diag{œÉd2,œÉŒ∏2}\\bm{V} = \\text{diag}\\left\\{\\sigma_d^2, \\sigma_\\theta^2\n\\right\\}."
  },
  {
    "objectID": "06_localization.html#estimating-pose",
    "href": "06_localization.html#estimating-pose",
    "title": "06_localization",
    "section": "Estimating pose",
    "text": "Estimating pose"
  },
  {
    "objectID": "06_localization.html#estimating-pose-1",
    "href": "06_localization.html#estimating-pose-1",
    "title": "06_localization",
    "section": "Estimating pose",
    "text": "Estimating pose\n\n\n\nShip‚Äôs navigator problem\n\n\nHow to estimate our new pose given the previous pose and noise odometry?\n\n\n\n\nThe mathematical tool that we will use is the Kalman filter.\n\nprovides the optimal estimate of the system state assuming zero-mean Gaussian noise.\n\nThe filter is a recursive algorithm that updates, at each time step, the optimal estimate of the unknown true configuration and the uncertainty associated with that estimate.\nThe Kalman filter is formulated for linear systems but our model of the vehicle‚Äôs motion is nonlinear, so we‚Äôll use the extended Kalman filter (EKF).\nFor this problem, the state vector is the vehicle‚Äôs configuration ùê±=(xv,yv,Œ∏v) \\bm{x} =\n\\left(x_v, y_v, \\theta_v \\right)  and the prediction equations ùê±ÃÇ+‚ü®k+1‚ü©=ùêü(ùê±ÃÇ‚ü®k‚ü©,ùêÆÃÇ‚ü®k‚ü©)ùêèÃÇ+‚ü®k+1‚ü©=ùêÖxùêèÃÇ‚ü®k‚ü©ùêÖx‚ä§+ùêÖvùêïÃÇùêÖv‚ä§\n\\begin{aligned}\n\\hat{\\bm{x}}^+\\langle k+1 \\rangle &= \\bm{f}\\left(\\hat{\\bm{x}}\\langle k \\rangle,\n\\hat{\\bm{u}}\\langle k \\rangle \\right) \\\\\n\\hat{\\bm{P}}^+\\langle k+1 \\rangle &= \\bm{F}_x\\hat{\\bm{P}}\\langle k\n\\rangle \\bm{F}_x^\\top + \\bm{F}_v \\hat{\\bm{V}}\\bm{F}_v^\\top\n\\end{aligned}\n describe how the state and covariance evolve with time."
  },
  {
    "objectID": "06_localization.html#estimating-pose-2",
    "href": "06_localization.html#estimating-pose-2",
    "title": "06_localization",
    "section": "Estimating pose",
    "text": "Estimating pose\nùê±ÃÇ+‚ü®k+1‚ü©=ùêü(ùê±ÃÇ‚ü®k‚ü©,ùêÆÃÇ‚ü®k‚ü©)ùêèÃÇ+‚ü®k+1‚ü©=ùêÖxùêèÃÇ‚ü®k‚ü©ùêÖx‚ä§+ùêÖvùêïÃÇùêÖv‚ä§\n\\begin{aligned}\n\\hat{\\bm{x}}^+\\langle k+1 \\rangle &= \\bm{f}\\left(\\hat{\\bm{x}}\\langle k \\rangle,\n\\hat{\\bm{u}}\\langle k \\rangle \\right) \\\\\n\\hat{\\bm{P}}^+\\langle k+1 \\rangle &= \\bm{F}_x\\hat{\\bm{P}}\\langle k\n\\rangle \\bm{F}_x^\\top + \\bm{F}_v \\hat{\\bm{V}}\\bm{F}_v^\\top\n\\end{aligned}\n\n\nùêÆÃÇ‚ü®k‚ü©\\hat{\\bm{u}}\\langle k \\rangle: input to the process; in this case is the measured odometry, so ùêÆÃÇ‚ü®k‚ü©=Œ¥‚ü®k‚ü©\\hat{\\bm{u}}\\langle k \\rangle = \\delta \\langle k \\rangle.\nùêèÃÇ‚àà‚Ñù3√ó3\\hat{\\bm{P}} \\in \\mathbb{R}^{3 \\times 3} is a covariance matrix representing the uncertainty in the estimated vehicle configuration.\nùêïÃÇ\\hat{\\bm{V}} is our estimate of the covariance of the odometry noise, which in reality, we do not know.\nùêÖx\\bm{F}_x and ùêÖv\\bm{F}_v are Jacobian matrices obtained by differentiating the equations of motion and evaluating the result at ùêØ=0\\bm{v} = 0, giving ùêÖx=‚àÇùêü‚àÇùê±|ùêØ=0=(10‚àíŒ¥dsinŒ∏v01Œ¥dcosŒ∏v001)ùêÖv=‚àÇùêü‚àÇùêØ|ùêØ=0=(cosŒ∏v0sinŒ∏v001)\n\\begin{aligned}\n\\bm{F}_x &= \\frac{\\partial \\bm{f}}{\\partial \\bm{x}}\\vert_{\\bm{v}=0} =\n\\begin{pmatrix}\n1 & 0 & -\\delta_d \\sin{\\theta_v} \\\\ 0 & 1 & \\delta_d \\cos{\\theta_v} \\\\ 0 & 0 & 1\n\\end{pmatrix} \\\\\n\\bm{F}_v &= \\frac{\\partial \\bm{f}}{\\partial \\bm{v}}\\vert_{\\bm{v}=0} = \n\\begin{pmatrix}\n\\cos{\\theta_v} & 0 \\\\ \\sin{\\theta_v} & 0 \\\\ 0 & 1\n\\end{pmatrix}\n\\end{aligned}\n which are functions of the current state and odometry."
  },
  {
    "objectID": "06_localization.html#estimating-pose-3",
    "href": "06_localization.html#estimating-pose-3",
    "title": "06_localization",
    "section": "Estimating pose",
    "text": "Estimating pose\n\n\n\nThe true (blue) and estimated (red) robot path is shown in the figure to the right.\n\n95%95\\% confidence ellipses are indicated in green.\nThat is there is 95%95\\% chance that the robot‚Äôs xx- and yy-coordinate is within ¬±2œÉ\\pm 2\\sigma bound.\n\nThere are off-diagonal terms in the correlation matrix, which indicate that the uncertainties between the corresponding variables are related.\n\nFor example, the value P1,3=P3,1=‚àí0.5575P_{1,3}=P_{3,1} = -0.5575 indicates the uncertainties in xx and Œ∏\\theta are related.\n\nThe total uncertainty is given by det(ùêèÃÇ)\\sqrt{\\det{(\\hat{\\bm{P}})}} and is plotted.\n\nIt never decreases because RHS of the ùêèÃÇ\\hat{\\bm{P}} eqn. is positive definite.\nMeans that ùêè\\bm{P}, the position uncertainty can never decrease!"
  },
  {
    "objectID": "06_localization.html#localizing-with-a-map-1",
    "href": "06_localization.html#localizing-with-a-map-1",
    "title": "06_localization",
    "section": "Localizing with a map",
    "text": "Localizing with a map\n\nRecall: uncertainty in position grows without bound using dead-reckoning alone.\nThe solution, as the Phoenicians worked out 4,0004,000 years ago, is to bring in additional information from observations of known features in the world.\n\nIn the examples, we will use a map that contains NN fixed but randomly located landmarks whose positions are known.\n\nThe robot is equipped with a sensor that provides observations of the landmarks w.r.t. the robot, described by ùê≥=ùê°(ùê±,ùê©i), \\bm{z} = \\bm{h}(\\bm{x}, \\bm{p}_i),  where ùê©i=(xi,yi)‚ä§\\bm{p}_i = \\left(x_i, y_i\\right)^\\top is the known location of the ithi^{\\text{th}} landmark in the world frame.\nTo make this concrete, let‚Äôs consider a common type of sensor that measures the range and bearing angle to a landmark in the environment\n\nsuch as a radar or a scanning-laser rangefinder.\n\n\n\n\n\nObservation of the ithi^{\\text{th}} landmark\n\n\nùê≥=ùê°(ùê±,ùê©i)=((yi‚àíyv)2+(xi‚àíxv)2arctan(yi‚àíyv,xi‚àíxv)‚àíŒ∏v)+(wrwŒ≤)\n\\bm{z} = \\bm{h}(\\bm{x}, \\bm{p}_i) = \n\\begin{pmatrix}\n\\sqrt{ \\left(y_i - y_v \\right)^2 + \\left(x_i - x_v\\right)^2 } \\\\ \n\\arctan{\\left(y_i-y_v, x_i-x_v\\right)} - \\theta_v\n\\end{pmatrix} + \n\\begin{pmatrix} w_r \\\\ w_\\beta \\end{pmatrix}"
  },
  {
    "objectID": "06_localization.html#localizing-with-a-map-2",
    "href": "06_localization.html#localizing-with-a-map-2",
    "title": "06_localization",
    "section": "Localizing with a map",
    "text": "Localizing with a map\n\n\n\nObservation of the ithi^{\\text{th}} landmark\n\n\nùê≥=ùê°(ùê±,ùê©i)=((yi‚àíyv)2+(xi‚àíxv)2arctan(yi‚àíyv,xi‚àíxv)‚àíŒ∏v)+(wrwŒ≤)\n\\bm{z} = \\bm{h}(\\bm{x}, \\bm{p}_i) = \n\\begin{pmatrix}\n\\sqrt{ \\left(y_i - y_v \\right)^2 + \\left(x_i - x_v\\right)^2 } \\\\ \n\\arctan{\\left(y_i-y_v, x_i-x_v\\right)} - \\theta_v\n\\end{pmatrix} + \n\\begin{pmatrix} w_r \\\\ w_\\beta \\end{pmatrix}\n\n\n\n\n\nùê≥=(r,Œ≤)‚ä§\\bm{z} = (r, \\beta)^\\top, rr is the range, Œ≤\\beta is the bearing angle.\nùê∞=(wr,wŒ≤)‚ä§‚àºùí©(0,ùêñ),ùêñ=diag{œÉr2,œÉŒ≤2}\\bm{w} = \\left(w_r, w_\\beta\\right)^\\top \\sim \\mathcal{N}(0, \\bm{W}), \\;\\;\n\\bm{W} = \\text{diag}\\{ \\sigma_r^2, \\sigma_\\beta^2 \\}: constant covariance matrix.\nIn implementation, this sensor return the range and bearing to some landmark along with its identity (to avoid data association problem).\n\nRecall: the location (xi,yi)(x_i, y_i) of the measured landmark is known in the world frame.\n\nUsing the equation above, the robot can estimate the range and bearing angle to the landmark based on its own estimated position and the known position of the landmark from the map.\nAny difference between the observation ùê≥‚ôØ\\bm{z}^\\sharp and the estimated observation indicates an error in the robot‚Äôs pose estimate ùê±ÃÇ\\hat{\\bm{x}} ‚Äì it isn‚Äôt where it thought it was!"
  },
  {
    "objectID": "06_localization.html#localizing-with-a-map-3",
    "href": "06_localization.html#localizing-with-a-map-3",
    "title": "06_localization",
    "section": "Localizing with a map",
    "text": "Localizing with a map\n\nThis difference\n\n\n\n\nObservation error\n\n\nùõé‚ü®k‚ü©=ùê≥‚ôØ‚ü®k‚ü©‚àíùê°(ùê±ÃÇ‚ü®k‚ü©,ùê©i)\n\\bm{\\nu}\\langle k \\rangle = \\bm{z}^\\sharp \\langle k \\rangle - \\bm{h}\\left(\\hat{{\\bm{x}}} \n\\langle k \\rangle, \\bm{p}_i \\right)\n\n\n\n\nis key to the operation of the Kalman filter.\n\nIt is called the innovation since it represents new information.\nKalman filter uses the innovation to correct the state estimate and update the uncertainty estimate in an optimal way.\nThe predicted state, computed earlier, is updated by\n\n\n\n\nKalman filter update equations\n\n\nùê±ÃÇ‚ü®k+1‚ü©=ùê±ÃÇ+‚ü®k+1‚ü©+ùêäùõé‚ü®k+1‚ü©ùêèÃÇ‚ü®k+1‚ü©=ùêèÃÇ+‚ü®k+1‚ü©‚àíùêäùêáxùêèÃÇ+‚ü®k+1‚ü©\n\\begin{aligned}\n\\hat{\\bm{x}} \\langle k+1 \\rangle &= \\hat{\\bm{x}}^+ \\langle k+1 \\rangle +\n\\bm{K}\\bm{\\nu}\\langle k + 1 \\rangle \\\\\n\\hat{\\bm{P}} \\langle k+1 \\rangle &= \\hat{\\bm{P}}^+ \\langle k+1 \\rangle -\n\\bm{K}\\bm{H}_x\\hat{\\bm{P}}^+ \\langle k+1 \\rangle\n\\end{aligned}"
  },
  {
    "objectID": "06_localization.html#localizing-with-a-map-4",
    "href": "06_localization.html#localizing-with-a-map-4",
    "title": "06_localization",
    "section": "Localizing with a map",
    "text": "Localizing with a map\n\n\n\nKalman filter update equations\n\n\nùê±ÃÇ‚ü®k+1‚ü©=ùê±ÃÇ+‚ü®k+1‚ü©+ùêäùõéùêèÃÇ‚ü®k+1‚ü©=ùêèÃÇ+‚ü®k+1‚ü©‚àíùêäùêáxùêèÃÇ+‚ü®k+1‚ü©\n\\begin{aligned}\n\\hat{\\bm{x}} \\langle k+1 \\rangle &= \\hat{\\bm{x}}^+ \\langle k+1 \\rangle +\n\\bm{K}\\bm{\\nu} \\\\\n\\hat{\\bm{P}} \\langle k+1 \\rangle &= \\hat{\\bm{P}}^+ \\langle k+1 \\rangle -\n\\bm{K}\\bm{H}_x\\hat{\\bm{P}}^+ \\langle k+1 \\rangle\n\\end{aligned}\n\n\n\n\n\nThese take the predicted values for the next time step, denoted with the +{~}^+ and compute the optimal estimate by applying landmark measurement from step k+1k+1.\n\n\n\n\nKalman gain\n\n\nùêä=ùêè+‚ü®k+1‚ü©ùêáx‚ä§ùêí‚àí1ùêí=ùêáxùêè+‚ü®k+1‚ü©ùêáx‚ä§+ùêáwùêñÃÇùêáw‚ä§\n\\begin{aligned}\n\\bm{K} &= \\bm{P}^+ \\langle k+1 \\rangle \\bm{H}_x^\\top \\bm{S}^{-1} \\\\\n\\bm{S} &= \\bm{H}_x \\bm{P}^+ \\langle k+1 \\rangle \\bm{H}_x^\\top + \\bm{H}_w\n\\hat{\\bm{W}} \\bm{H}_w^\\top\n\\end{aligned}\n\n\n\n\nwhere ùêñÃÇ\\hat{\\bm{W}} is the estimated covariance of the sensor noise and ùêáx\\bm{H}_x and ùêáw\\bm{H}_w are Jacobians\nùêáx=‚àÇùê°‚àÇùê±|ùê∞=0=(‚àí1r(xi‚àíxv)‚àí1r(yi‚àíyv)01r(yi‚àíyv)‚àí1r(xi‚àíxv)‚àí1),ùêáw=‚àÇùê°‚àÇùê∞|ùê∞=0=(1001).\n\\bm{H}_x = \\frac{\\partial \\bm{h}}{\\partial \\bm{x}}\\vert_{\\bm{w}=0} = \n\\begin{pmatrix}\n-\\frac{1}{r}\\left(x_i - x_v\\right) & -\\frac{1}{r}\\left(y_i - y_v\\right) & 0 \\\\\n\\frac{1}{r}\\left(y_i - y_v\\right) & -\\frac{1}{r}\\left(x_i - x_v\\right) & -1\n\\end{pmatrix}, \\quad\\quad\n\\bm{H}_w = \\frac{\\partial \\bm{h}}{\\partial \\bm{w}}\\vert_{\\bm{w}=0} = \n\\begin{pmatrix}\n1 & 0 \\\\ 0 & 1\n\\end{pmatrix}."
  },
  {
    "objectID": "06_localization.html#localizing-with-a-map-5",
    "href": "06_localization.html#localizing-with-a-map-5",
    "title": "06_localization",
    "section": "Localizing with a map",
    "text": "Localizing with a map\n\n\n¬†\n\nThe Kalman gain matrix ùêä\\bm{K} distributes the innovation from the landmark observation, a 22-vector, to update every element of the state vector.\nNote that the second term in the covariance update equation is subtracted from the estimated covariance.\n\nThis provides a means for estimated covariance to decrease, which was not possible for the dead-reckoning case."
  },
  {
    "objectID": "06_localization.html#localizing-with-a-map-6",
    "href": "06_localization.html#localizing-with-a-map-6",
    "title": "06_localization",
    "section": "Localizing with a map",
    "text": "Localizing with a map\n\n\n\nEKF localization\n\nBlue: true path of the robot,\nRed: estimated path from odometry and landmarks,\nStars: landmarks.\n\nThe error ellipses are now much smaller ‚Äì many can hardly be seen.\nThe bottom figure shows a zoomed view of the robot‚Äôs actual and estimated path (moving from top to bottom).\n\nThe error ellipses grow as the robot moves and then shrinks just after a jag in the estimated path.\nThis corresponds to the observation of a landmark.\nNew information, beyond odometry, has been used to correct the state in the Kalman filter update phase."
  },
  {
    "objectID": "06_localization.html#localizing-with-a-map-7",
    "href": "06_localization.html#localizing-with-a-map-7",
    "title": "06_localization",
    "section": "Localizing with a map",
    "text": "Localizing with a map\n\n\n\nOverall uncertainty is no longer growing monotonically\n\nWhen the robot sees a landmark, it is able to dramatically reduce its estimated covariance.\n\nThe bottom figure shows the error associated with each component of pose\n\nThe pink background is estimated 95%95\\% confidence bound (derived from the covariance matrix).\nNotice the error is mostly within this envelope.\n\nBelow this is plotted the landmark observations\n\nNotice that the confidence bounds are tight (indicating low uncertainty) while landmarks are being observed.\nThey start to grow once observations stop.\nAs soon as an observation is made the uncertainty rapidly decreases."
  },
  {
    "objectID": "06_localization.html#creating-a-map-1",
    "href": "06_localization.html#creating-a-map-1",
    "title": "06_localization",
    "section": "Creating a map",
    "text": "Creating a map\n\nSomebody or something has to create the maps we will use.\n\n\n\n\nAssumptions:\n\n\n\nSensor can determine the identity of each observed landmark.\nThe robot knows its own position perfectly (ideal localization).\n\n\n\n\n\nWe need to estimate the coordinates of the landmarks. Hence for this problem, the state vector comprises the estimated coordinates of the MM landmarks we have observed so far: ùê±ÃÇ=(x1,y1,x2,y2,‚Ä¶,xM,yM)‚àà‚Ñù2M√ó1. \\hat{\\bm{x}} = \\left(x_1, y_1, x_2, y_2, \\ldots, x_M, y_M \\right)\n\\in \\mathbb{R}^{2M \\times 1}. \nThe corresponding estimated covariance ùêèÃÇ\\hat{\\bm{P}} will be a 2M√ó2M2M \\times 2M matrix.\nThe state vector has variable length since we do not know in advance how many landmarks exist.\n\nInitially M=0M = 0 and is incremented every time a previously unseen landmark is observed."
  },
  {
    "objectID": "06_localization.html#creating-a-map-2",
    "href": "06_localization.html#creating-a-map-2",
    "title": "06_localization",
    "section": "Creating a map",
    "text": "Creating a map\n\nThe prediction equation is straightforward since the landmarks are stationary. ùê±ÃÇ‚ü®k+1‚ü©=ùê±ÃÇ‚ü®k‚ü©ùêèÃÇ+‚ü®k+1‚ü©=ùêèÃÇ‚ü®k‚ü©\n\\begin{aligned}\n\\hat{\\bm{x}} \\langle k+1 \\rangle &= \\hat{\\bm{x}} \\langle k \\rangle \\\\\n\\hat{\\bm{P}}^+ \\langle k+1 \\rangle &= \\hat{\\bm{P}} \\langle k \\rangle\n\\end{aligned}\n\nWe introduce the function ùê†(‚ãÖ)\\bm{g}(\\cdot), the inverse of ùê°(‚ãÖ)\\bm{h}(\\cdot), which gives the coordinates of the observed landmark based on the known vehicle pose and the sensor observation ùê†(ùê±,ùê≥)=(xv+rcos(Œ∏v+Œ≤)yv+rsin(Œ∏v+Œ≤)) \\bm{g}(\\bm{x}, \\bm{z}) = \\begin{pmatrix}\nx_v + r \\cos{\\left(\\theta_v + \\beta\\right)} \\\\\ny_v + r \\sin{\\left(\\theta_v + \\beta\\right)}\n\\end{pmatrix} \nSince ùê±ÃÇ\\hat{\\bm{x}} has a variable length, we need to extend the state vector and the covariance matrix whenever we encounter a previously unseen landmark. ùê±‚ü®k‚ü©‚Ä≤=ùê≤(ùê±‚ü®k‚ü©,ùê≥‚ü®k‚ü©,ùê±v‚ü®k‚ü©)=(ùê±‚ü®k‚ü©ùê†(ùê±v‚ü®k‚ü©,ùê≥‚ü®k‚ü©)). \n\\bm{x} \\langle k \\rangle^\\prime = \\bm{y}\\left(\\bm{x} \\langle k \\rangle,\n\\bm{z}\\langle k \\rangle, \\bm{x}_v \\langle k \\rangle \\right) \n= \\begin{pmatrix}\n\\bm{x} \\langle k \\rangle \\\\\n\\bm{g} \\left(\\bm{x}_v \\langle k \\rangle, \\bm{z} \\langle k \\rangle \\right)\n\\end{pmatrix}.\n\n\nThis appends the sensor-based estimate of the new landmark‚Äôs coordinates to those already in the map.\nThe order of feature coordinates within ùê±ÃÇ\\hat{\\bm{x}} therefore depends on the order in which they are observed."
  },
  {
    "objectID": "06_localization.html#creating-a-map-3",
    "href": "06_localization.html#creating-a-map-3",
    "title": "06_localization",
    "section": "Creating a map",
    "text": "Creating a map\n\nThe covariance matrix also needs to be extended when a new landmark is observed and this is achieved by ùêèÃÇ‚ü®k‚ü©‚Ä≤=ùêòz(ùêèÃÇ‚ü®k‚ü©ùüé2√óMùüé2√óMùêñÃÇ)ùêòz‚ä§ \\hat{\\bm{P}} \\langle k \\rangle^\\prime = \\bm{Y}_z \\begin{pmatrix}\n\\hat{\\bm{P}}\\langle k \\rangle & \\bm{0}_{2\\times M} \\\\ \\bm{0}_{2\\times M} & \n\\hat{\\bm{W}} \\end{pmatrix} \\bm{Y}_z^\\top  where ùêòz\\bm{Y}_z is the insertion Jacobian ùêòz=‚àÇùê≤‚àÇùê≥=(ùêàM√óMùüéM√ó2ùêÜxùüé2√ó(M‚àí3)ùêÜz) \\bm{Y}_z =\n\\frac{\\partial \\bm{y}}{\\partial \\bm{z}} = \\begin{pmatrix} \\bm{I}_{M \\times M} &\n& \\bm{0}_{M \\times 2} \\\\ \\bm{G}_x & \\bm{0}_{2 \\times (M-3)} & \\bm{G}_z\n\\end{pmatrix}  that relates the rate of change of the extended state vector to the new observation, and\n\nùêÜx=‚àÇùê†‚àÇùê±=(000000),ùêÜz=‚àÇùê†‚àÇùê≥=(cos(Œ∏v+Œ≤)‚àírsin(Œ∏v+Œ≤)sin(Œ∏v+Œ≤)rcos(Œ∏v+Œ≤))\n\\bm{G}_x = \\frac{\\partial \\bm{g}}{\\partial \\bm{x}} = \\begin{pmatrix} 0 & 0 & 0\n\\\\ 0 & 0 & 0 \\end{pmatrix}, \\quad\\quad\n\\bm{G}_z = \\frac{\\partial \\bm{g}}{\\partial \\bm{z}} = \\begin{pmatrix} \n\\cos{\\left(\\theta_v + \\beta\\right)} & -r\\sin{\\left(\\theta_v + \\beta\\right)} \\\\\n\\sin{\\left(\\theta_v + \\beta\\right)} & r\\cos{\\left(\\theta_v + \\beta\\right)}\n\\end{pmatrix}\n\n\nAn additional Jacobian for ùê°(‚ãÖ)\\bm{h(\\cdot)} is ùêápi\\bm{H}_{p_i} and ùêáx\\bm{H}_x looks like ùê°(‚ãÖ)\\bm{h}(\\cdot) ùêápi=‚àÇùê°‚àÇùê©i=(1r(xi‚àíxv)1r(yi‚àíyv)‚àí1r2(yi‚àíyv)1r2(xi‚àíxv));ùêáx=[ùüé2√ó2‚ãØùêápi‚ãØùüé2√ó2] \\bm{H}_{p_i} = \\frac{\\partial \\bm{h}}{\\partial \\bm{p}_i} = \\begin{pmatrix} \n\\frac{1}{r}\\left(x_i - x_v\\right) & \\frac{1}{r}\\left(y_i - y_v\\right) \\\\\n-\\frac{1}{r^2}\\left(y_i - y_v\\right) & \\frac{1}{r^2}\\left(x_i - x_v\\right)\n\\end{pmatrix}; \\quad \\bm{H}_x = \\begin{bmatrix}\\bm{0}_{2\\times 2} & \\cdots & \n\\bm{H}_{p_i} & \\cdots & \\bm{0}_{2 \\times 2}\\end{bmatrix} \nùêáx\\bm{H}_x describes how the landmark observation changes w.r.t. the full state vector."
  },
  {
    "objectID": "06_localization.html#creating-a-map-4",
    "href": "06_localization.html#creating-a-map-4",
    "title": "06_localization",
    "section": "Creating a map",
    "text": "Creating a map\n\n\n\n\n\n\nEKF mapping results\n\n\nThe estimated landmarks are indicated by black dots with 95%95\\% confidence ellipses (green, hard to see w/o zooming), the true location (black star marker) and the robot‚Äôs path (blue). The landmark estimates have not fully converged to their true values."
  },
  {
    "objectID": "06_localization.html#simultaneous-localization-and-mapping",
    "href": "06_localization.html#simultaneous-localization-and-mapping",
    "title": "06_localization",
    "section": "Simultaneous localization and mapping",
    "text": "Simultaneous localization and mapping\n\nFeels like a ‚Äò‚Äôchicken and egg‚Äô‚Äô problem\n\nwe need a map to localize and\nwe need to localize to make a map.\n\nHowever, based on what we have learned so far this problem is now quite straightforward to solve.\nThe state vector comprises the vehicle configuration and the coordinates of the MM landmarks that have been observed so far ùê±ÃÇ=(xv,yv,Œ∏v,x1,y1,x2,y2,‚Ä¶,xM,yM)‚ä§‚àà‚Ñù2M+3√ó1 \\hat{\\bm{x}} =\n\\left(x_v, y_v, \\theta_v, x_1, y_1, x_2, y_2, \\ldots, x_M, y_M \\right)^\\top \\in\n\\mathbb{R}^{2M+3 \\times 1} \nThe estimated covariance is a (2M+3)√ó(2M+3)(2M+3) \\times (2M+3) matrix and has the structure ùêèÃÇ=(ùêèÃÇvvùêèÃÇvmùêèÃÇvm‚ä§ùêèÃÇmm) \\hat{\\bm{P}} = \\begin{pmatrix} \\hat{\\bm{P}}_{vv} &\n\\hat{\\bm{P}}_{vm} \\\\ \\hat{\\bm{P}}_{vm}^\\top & \\hat{\\bm{P}}_{mm} \\end{pmatrix}  where ùêèÃÇvv\\hat{\\bm{P}}_{vv} is the covariance of the vehicle pose, ùêèÃÇmm\\hat{\\bm{P}}_{mm} the covariance of the map landmark positions, and ùêèÃÇvm\\hat{\\bm{P}}_{vm} is the correlation between vehicle landmark states."
  },
  {
    "objectID": "06_localization.html#slam",
    "href": "06_localization.html#slam",
    "title": "06_localization",
    "section": "SLAM",
    "text": "SLAM\n\nThe predicted vehicle state and covariances are as they were given in localization section with perfect map knowledge.\nWhen a new feature is observed the state vector is updated using the insertion Jacobian ùêòz\\bm{Y}_z but in this case ùêÜx\\bm{G}_x is nonzero ùêÜx=‚àÇùê†‚àÇùê±=(10‚àírsin(Œ∏v+Œ≤)01rcos(Œ∏v+Œ≤)) \\bm{G}_x = \\frac{\\partial \\bm{g}}{\\partial \\bm{x}} = \\begin{pmatrix} \n1 & 0 & -r \\sin{\\left(\\theta_v + \\beta\\right)} \\\\\n0 & 1 & r \\cos{\\left(\\theta_v + \\beta\\right)} \\end{pmatrix}  since the estimate of the new landmark depends on the state vector which now contains the vehicle‚Äôs pose.\nFor SLAM, the Jacobian ùêáx\\bm{H}_x describes how the landmark observation changes w.r.t. the state vector. The observation will depend on the position of the vehicle and on the position of the observed landmark ùêáx=‚àÇùê°‚àÇùê±|w=0=(ùêáxv‚ãØùüé2√ó2‚ãØùêápi‚ãØùüé2√ó2)‚àà‚Ñù2√ó(2M+3). \\bm{H}_x =\n\\frac{\\partial \\bm{h}}{\\partial \\bm{x}}\\vert_{w=0} = \\begin{pmatrix}\n\\bm{H}_{x_v} & \\cdots & \\bm{0}_{2 \\times 2} & \\cdots & \\bm{H}_{p_i} & \\cdots & \n\\bm{0}_{2 \\times 2} \\end{pmatrix} ‚àà \\mathbb{R}^{2 \\times \\left(2M+3\\right)}. \nNow, the Kalman gain matrix ùêä\\bm{K} distributes innovation from the landmark observation, a 22-vector, to update every element of the state vector ‚Äì the pose of the vehicle and the position of every landmark in the map."
  },
  {
    "objectID": "06_localization.html#slam-results",
    "href": "06_localization.html#slam-results",
    "title": "06_localization",
    "section": "SLAM ‚Äì results",
    "text": "SLAM ‚Äì results\n\n\n\n\n\nSLAM ‚Äì path\n\n\nSimultaneous localization and mapping showing the true (blue) and estimated (red) robot path superimposed on the true map (black star marker). The estimated map features are indicated by black dots with 95%95\\% confidence ellipses (green).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSLAM ‚Äì covariance\n\n\nThe final covariance matrix is shown graphically on the right. The landmark uncertainties never increase.\nThe position prediction model is that they do not move, but they also never drop below the initial uncertainty of the vehicle.\n\n\n\n\n\nThe correlations are used by the Kalman filter to connect the observation of any landmark to an improvement in the estimate of every other landmark in the map as well as the vehicle pose. It is as if all the states were connected by springs."
  },
  {
    "objectID": "06_localization.html#pose-graph-slam-1",
    "href": "06_localization.html#pose-graph-slam-1",
    "title": "06_localization",
    "section": "Pose Graph SLAM",
    "text": "Pose Graph SLAM\n\nAn alternative approach to the SLAM problem is to separate it into two components:\n\nA front-end and a back-end, connected by a pose graph.\nFront end adds new vertices as the robot travels as well as edges that define constraints between vertices.\n\nOdometry gives an estimate of distance and change in orientation\nExteroceptive sensors observe relative position of a landmark adding a constraint.\n\nBack end runs periodically to optimize the pose graph and adjusts poses of the vertices so that the constraints are satisfied as well as possible."
  },
  {
    "objectID": "06_localization.html#pose-graph-slam-fundamentals",
    "href": "06_localization.html#pose-graph-slam-fundamentals",
    "title": "06_localization",
    "section": "Pose Graph SLAM Fundamentals",
    "text": "Pose Graph SLAM Fundamentals\n\n\n\nRobot‚Äôs path: a seq. of distinct poses to be estimated.\nTwo types of poses: robot poses, landmarks positions.\n\n\n\n\nDead-reckoning example\n\n\nAs the robot progresses counter-clockwise around the square, it compounds an increasing number of uncertain relative poses from odometry so that the cumulative error in the estimated pose of the vertices is increasing (we assume ùõèÃÇ0=ùõè0\\hat{\\bm{\\xi}}_0 = \\bm{\\xi}_0).\nBy the time the robot reaches the fourth positionthe pose error is singificant.\nHowever, it is able to observe landmark A, which it saw previously and this adds the constraint shown in red, which forms a loop in the pose graph.\nThis type of event is referred to as loop closure.\n\n\n\n\nThe estimate ùê†(ùõèÃÇ0,ùê≥0,A)\\bm{g}(\\bm{\\hat{\\xi}}_0, \\bm{z}_{0, A}) is subject to sensor error.\n\n\n\n\n\n\n\n\nPose-graph SLAM example\n\n\nRobot poses shown as circular nodes.\nLandmarks are shown as star-shaped nodes.\nAn edge betw. two vertices represents a spatial constraint between them due to some observation ùê≥i,j\\bm{z}_{i,j}.\n\n\n\n\n\nThe estimate ùê†(ùõèÃÇ3,ùê≥3,A)\\bm{g}(\\bm{\\hat{\\xi}}_3, \\bm{z}_{3, A}) is subject to sensor and accumulated odometry error in ùõèÃÇ3\\hat{\\bm{\\xi}}_3, which can be used to produce an error to be minimized."
  },
  {
    "objectID": "06_localization.html#pose-graph-slam-fundamentals-1",
    "href": "06_localization.html#pose-graph-slam-fundamentals-1",
    "title": "06_localization",
    "section": "Pose Graph SLAM Fundamentals",
    "text": "Pose Graph SLAM Fundamentals\n\n\n\nThere is typically insufficient information to determine exactly where the error lies.\n\nNaively adjusting ùõèÃÇ3\\bm{\\hat{\\xi}}_3 to fit the landmark observation might increase the error in another part of the graph.\nWe need to minimize the error consistently over the whole graph.\n\nLet‚Äôs consider first the case w/o landmarks. The state vector contains the poses of all the vertices:\n\nùê±={ùõè0,ùõè1,‚Ä¶,ùõèN‚àí1} \\bm{x} = \\left\\{ \\bm{\\xi}_0, \\bm{\\xi}_1, \\ldots, \\bm{\\xi}_{N-1} \\right\\} \nand we seek an estimate ùê±ÃÇ\\hat{\\bm{x}} that minimizes the error across all the edges.\nùê±*=argminùê±‚àëkFk(ùê±) \\bm{x}^* = \\arg \\min_\\bm{x} \\sum_k F_k(\\bm{x}) \nwhere Fk(ùê±)‚àà‚Ñù‚â•0F_k(\\bm{x}) \\in \\mathbb{R}_{\\geq 0} is a cost associated with the edge kk.\n\n\n\n\n\n\n\nPose-graph SLAM example\n\n\nRobot poses shown as circular nodes.\nLandmarks are shown as star-shaped nodes.\nAn edge betw. two vertices represents a spatial constraint between them due to some observation ùê≥i,j\\bm{z}_{i,j}.\n\n\n\n\n\nThe term that we are minimizing is the total edge error that is analogous to the potential energy in a flexible structure which we want to relax into a minimum energy state."
  },
  {
    "objectID": "06_localization.html#pose-graph-slam-forming-the-odom.-error",
    "href": "06_localization.html#pose-graph-slam-forming-the-odom.-error",
    "title": "06_localization",
    "section": "Pose Graph SLAM: Forming the Odom. Error",
    "text": "Pose Graph SLAM: Forming the Odom. Error\n\n\n\nWe have two values for the relative pose btw. the vertices:\n\nThe explicit sensor measurement ùê≥i,j\\bm{z}_{i,j},\n(Dashed) Implicit based on the current estimates from the pose-graph.\nAny difference btw. the two indicates that one or both vertices need to be moved.\n\nThe relative pose - based on current estimates in the pose graph iùõèÃÇj=‚äñùõèÃÇi‚äïùõèÃÇj‚ààùêíùêÑ(2) {^i}\\hat{\\bm{\\xi}}_j = \\ominus \\hat{\\bm{\\xi}}_i \\oplus \\hat{\\bm{\\xi}}_j \\in \\bm{SE}(2)  which we can write as an SE(2) matrix iùêìj{^i}\\bm{T}_j.\nWe can also estimate the relative pose from the odometry observation ùê≥k=ùê≥i,j=(Œ¥d,Œ¥Œ∏)\\bm{z}_k = \\bm{z}_{i,j} = (\\delta_d, \\delta_\\theta).\n\nùêìz(ùê≥k)=[cosŒ¥Œ∏‚àísinŒ¥Œ∏Œ¥dcosŒ¥Œ∏sinŒ¥Œ∏cosŒ¥Œ∏Œ¥dsinŒ¥Œ∏001]\n\\bm{T}_z(\\bm{z}_k) = \\begin{bmatrix}\n\\cos{\\delta_\\theta} & -\\sin{\\delta_\\theta} & \\delta_d \\cos{\\delta_\\theta} \\\\\n\\sin{\\delta_\\theta} & \\cos{\\delta_\\theta} & \\delta_d \\sin{\\delta_\\theta} \\\\\n0 & 0 & 1\n\\end{bmatrix}\n\n\n\n\n\n\n\n\nPose-graph single edge error formation\n\n\n\nA single edge of the pose graph showing the estimated robot poses: ùõèÃÇi\\hat{\\bm{\\xi}}_i and ùõèÃÇj\\hat{\\bm{\\xi}}_j.\nThe relative pose based on the sensor measurement is ùê≥i,j\\bm{z}_{i,j}.\nThe implicit relative pose is shown as a dashed line."
  },
  {
    "objectID": "06_localization.html#pose-graph-slam-forming-the-odom.-error-1",
    "href": "06_localization.html#pose-graph-slam-forming-the-odom.-error-1",
    "title": "06_localization",
    "section": "Pose Graph SLAM: Forming the Odom. Error",
    "text": "Pose Graph SLAM: Forming the Odom. Error\n¬†\n\n\n\nThe difference btw. these two relative poses is ùêìe=ùêìz‚àí1iùêìj\\bm{T}_e = \\bm{T}_z^{-1}{^i}\\bm{T}_j:\n\nùêük(ùê±,ùê≥)=[ùêìz‚àí1(ùê≥i,j)ùêì‚àí1(ùê±i)ùêì(ùê±j)]xyŒ∏\n\\bm{f}_k(\\bm{x}, \\bm{z}) = \\left[\\bm{T}_z^{-1}(\\bm{z}_{i,j})\\bm{T}^{-1}(\\bm{x}_i)\\bm{T}(\\bm{x}_j) \\right]_{xy\\theta}\n\n\nThis configuration (xe,ye,Œ∏e)‚àà‚Ñù2√óùïä1(x_e, y_e, \\theta_e) \\in \\mathbb{R}^2 \\times \\mathbb{S}^1 will be zero if the observation and the relative pose of the vertices are equal.\nTo obtain the scalar cost from the error vector $#, we use a quadratic expression\n\nFk(ùê±,ùê≥k)=ùêük‚ä§ùõÄkùêük(ùê±,ùê≥k),\nF_k(\\bm{x}, \\bm{z}_k) = \\bm{f}_k^\\top \\bm{\\Omega}_k \\bm{f}_k(\\bm{x}, \\bm{z}_k), \n\nwhere ùõÄk\\bm{\\Omega}_k is a positive-definite information matrix used as a weighting term.\n\n\n\n\n\n\n\nPose-graph single edge error formation\n\n\n\nA single edge of the pose graph showing the estimated robot poses: ùõèÃÇi\\hat{\\bm{\\xi}}_i and ùõèÃÇj\\hat{\\bm{\\xi}}_j.\nThe relative pose based on the sensor measurement is ùê≥i,j\\bm{z}_{i,j}.\nThe implicit relative pose is shown as a dashed line."
  },
  {
    "objectID": "06_localization.html#pose-graph-slam-forming-the-meas.-error",
    "href": "06_localization.html#pose-graph-slam-forming-the-meas.-error",
    "title": "06_localization",
    "section": "Pose Graph SLAM: Forming the Meas. Error",
    "text": "Pose Graph SLAM: Forming the Meas. Error\n¬†\n\n\n\nLandmarks are described by a coordinate vector ùê©j‚àà‚Ñù2\\bm{p}_j \\in \\mathbb{R}^2.\nWe redefine the state vector to be ùê±={ùõè0,ùõè1,‚Ä¶,ùõèN‚àí1‚à£ùê©0,ùê©1,‚Ä¶,ùê©M‚àí1}. \\bm{x} = \\{ \\bm{\\xi}_0, \\bm{\\xi}_1, \\ldots, \\bm{\\xi}_{N-1} \\mid \\bm{p}_0, \\bm{p}_1, \\ldots, \\bm{p}_{M-1} \\}. \nThis includes NN robot poses and MM landmark positions.\nThe robot at pose ii observes landmark jj at range and bearing ùê≥i,j=(r‚ôØ,Œ≤‚ôØ)\\bm{z}_{i,j} = (r^\\sharp, \\beta^\\sharp). iùê©j‚ôØ=(r‚ôØcosŒ≤‚ôØ,r‚ôØsinŒ≤‚ôØ)‚àà‚Ñù2. {^i}\\bm{p}_j^\\sharp = \\left( r^\\sharp \\cos{\\beta^\\sharp}, r^\\sharp \\sin{\\beta^\\sharp} \\right) \\in \\mathbb{R}^2. \nThe estimated position of the landmark in frame {i}\\{i\\} can also be determined from the vertices of the pose graph iùê©ÃÇj=(‚äñ0ùõèÃÇi)‚ãÖùê©ÃÇj‚àà‚Ñù2. {^i}\\hat{\\bm{p}}_j = \\left( \\ominus {^0}\\hat{\\bm{\\xi}}_i\\right) \\cdot \\hat{\\bm{p}}_j \\in \\mathbb{R}^2. \nThe error vector is:\n\nùêük(ùê±,ùê≥k)=iùê©ÃÇj‚àíiùê©j‚ôØ‚àà‚Ñù2.\n\\bm{f}_k(\\bm{x}, \\bm{z}_k) = {^i}\\hat{\\bm{p}}_j - {^i}\\bm{p}_j^\\sharp \\in \\mathbb{R}^2.\n\n\n\n\n\n\n\n\nPose-graph single edge error formation\n\n\n\nA single edge of the pose graph showing the estimated robot pose ùõèÃÇi\\hat{\\bm{\\xi}}_i and the landmark position ùê©ÃÇj\\hat{\\bm{p}}_j.\nThe relative position based on the sensor measurement is ùê≥i,j\\bm{z}_{i,j}.\nThe implicit relative pose is shown as a dashed line."
  },
  {
    "objectID": "06_localization.html#complementary-filter-1",
    "href": "06_localization.html#complementary-filter-1",
    "title": "06_localization",
    "section": "Complementary filter",
    "text": "Complementary filter\n\n\n\nThey provide a means to fuse multiple independent noisy measurements of the same signal that have complementary spectral characteristics.\n\nŒº1\\mu_1: predominantly high frequency noise\nŒº2\\mu_2: predominantly low frequency disturbance\n\nChoose a pair of complementary transfer functions F1(s)+F2(s)=1 F_1(s) + F_2(s) = 1 \n\nF1(s)F_1(s): low-pass transfer function\nF2(s)F_2(s): high-pass transfer function\n\n\n\n\n\n\n\n\n\n\nThe filtered estimate is given by XÃÇ(s)=F1(s)Y1+F2(s)Y2=X(s)+F1(s)Œº1(s)+F2(s)Œº2(s). \\hat{X}(s) = F_1(s)Y_1 + F_2(s)Y_2 = X(s) + F_1(s)\\mu_1(s) + F_2(s)\\mu_2(s).\n\nThis type of filter is also known as distorsionless filtering since the signal x(t)x(t) is not distorted by the filter."
  },
  {
    "objectID": "06_localization.html#complementary-filter-2",
    "href": "06_localization.html#complementary-filter-2",
    "title": "06_localization",
    "section": "Complementary filter",
    "text": "Complementary filter\n\nComplementary filters are particularly well suited to fusing low bandwidth position measurements with high bandwidth rate measurements for first-order kinematic systems xÃá=u \\dot{x} = u  with typical measurement characteristics yx=L(s)x+Œºx,yu=u+Œºu+b(t) y_x = L(s)x + \\mu_x, \\qquad y_u = u + \\mu_u + b(t) \n\nL(s)L(s): low-pass filter associated with sensor characteristics,\nŒº\\mu: noise in both measurements,\nb(t)b(t) is a deterministic perturbation dominated by low-frequency content.\n\nL(s)‚âà1L(s) \\approx 1 over frequency range on which the measurement yxy_x is of interest.\nThe rate measurement is integrated: yus\\frac{y_u}{s} to obtain an estimate of the state and the noise and bias characteristics of the signal are dominantly low frequency effects.\nNow, choose: F1(s)=C(s)C(s)+s,F2(s)=1‚àíF1(s)=sC(s)+s F_1(s) = \\frac{C(s)}{C(s) + s}, \\qquad F_2(s) = 1 - F_1(s) = \\frac{s}{C(s) +\ns} \n\nC(s)C(s): all pass such that L(s)F1(s)‚âà1L(s)F_1(s) \\approx 1 over the bandwidth of L(s)L(s). Then XÃÇ(s)‚âàX(s)+F1(s)Œºx(s)+Œºu(s)+b(s)C(s)+s. \\hat{X}(s) \\approx X(s) + F_1(s)\\mu_x(s) + \\frac{\\mu_u(s) + b(s)}{C(s) +\ns}."
  },
  {
    "objectID": "06_localization.html#complementary-filter-3",
    "href": "06_localization.html#complementary-filter-3",
    "title": "06_localization",
    "section": "Complementary filter",
    "text": "Complementary filter\n\n\n\n\nThe filter structure is implemented by exploiting the complementary sensitivity structure of a linear feedback system subject to load disturbance.\n\nxÃÇ(s)=C(s)s+C(s)yx(s)+sC(s)+syu(s)s=T(s)yx(s)+S(s)yu(s)s \\hat{x}(s) = \\frac{C(s)}{s + C(s)} y_x(s) + \\frac{s}{C(s) + s}\n\\frac{y_u(s)}{s} = T(s)y_x(s) + S(s)\\frac{y_u(s)}{s}  where S(s)S(s) is the sensitivity function of the closed-loop system and T(s)T(s) is the complementary sensitivity.\n\nSimplest choice for feedback: C(s)=kpC(s) = k_p. In this case, the CL-dynamics of the filter are given by xÃÇÃá=yu+kp(yx‚àíxÃÇ). \\dot{\\hat{x}} = y_u + k_p(y_x - \\hat{x}). \nAssociated complementary filters associated with this choice are F1(s)=kps+kp, and F2(s)=ss+kp.F_1(s) = \\frac{k_p}{s+k_p}, \\quad \\text{ and } \\quad  F_2(s) = \\frac{s}{s + k_p}."
  },
  {
    "objectID": "06_localization.html#complementary-filter-4",
    "href": "06_localization.html#complementary-filter-4",
    "title": "06_localization",
    "section": "Complementary filter",
    "text": "Complementary filter\n\nIf the rate measurement bias, b(t)=b0b(t) = b_0, is a constant then it is natural to add an integrator to the compensator to make the system type I C(s)=kp+kis. C(s) = k_p + \\frac{k_i}{s}. \nA type I system will reject the constant load disturbance b0b_0 from the output.\nThe resulting dynamics are xÃÇÃá=yu‚àíbÃÇ+k(yx‚àíxÃÇ),bÃÇÃá=‚àíki(yx‚àíxÃÇ). \\dot{\\hat{x}} = y_u - \\hat{b} + k(y_x - \\hat{x}), \\qquad \\dot{\\hat{b}} =\n-k_i(y_x - \\hat{x}). \nConsider the Lyapunov function candidate ‚Ñí=12|x‚àíxÃÇ|2+12ki|b0‚àíbÃÇ|2. \\mathcal{L} = \\frac{1}{2} \\lvert x - \\hat{x}\\rvert^2 + \\frac{1}{2k_i}\\lvert b_0 - \\hat{b} \\rvert^2. \n\nAbusing the notation for the noise processes and using xÃÉ=x‚àíxÃÇ\\tilde{x} = x -\n\\hat{x} and bÃÉ=b0‚àíbÃÇ\\tilde{b} = b_0 - \\hat{b}, one has ddt‚Ñí=‚àíkp|xÃÉ|2‚àíŒºuxÃÉ+Œºx(bÃÉ‚àíkxÃÉ). \\frac{\\text{d}}{\\text{d}t} \\mathcal{L} = -k_p \\lvert \\tilde{x} \\rvert^2 -\n\\mu_u \\tilde{x} + \\mu_x \\left( \\tilde{b} - k \\tilde{x} \\right). \n\nIn the absence of noise, one may apply Lyapunov‚Äôs direct method to prove convergence of the state estimate.\n\nLaSalle‚Äôs invariance principle may be used to show that bÃÇ‚Üíb0\\hat{b} \\rightarrow\nb_0.\nWhen the underlying system is linear, the linear form of the feedback and adaptation law ensure that the CL system is linear and stability implies exponential stability."
  },
  {
    "objectID": "06_localization.html#complementary-filter-on-bmso3",
    "href": "06_localization.html#complementary-filter-on-bmso3",
    "title": "06_localization",
    "section": "Complementary filter on ùêíùêé(3)\\bm{SO}(3)",
    "text": "Complementary filter on ùêíùêé(3)\\bm{SO}(3)\n¬†\n\nEstimation of the roll and pitch angles from IMU using the complementary filter\n\n33-axis linear accelerometer\n33-axis gyro rates\n33-axis magnetometer"
  }
]