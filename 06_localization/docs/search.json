[
  {
    "objectID": "06_localization.html#robotics-and-automated-systems",
    "href": "06_localization.html#robotics-and-automated-systems",
    "title": "06_localization",
    "section": "Robotics and Automated Systems",
    "text": "Robotics and Automated Systems\n\n\nLocalization\n\n\n\nInstructor: Aykut Satici, Ph.D.Â \nÂ \n\nMechanical and Biomedical Engineering \nElectrical and Computer Engineering \nBoise State University, Boise, ID, USA\n\n\nTopics: \n\nDead Reckoning\nLocalizing with a Map\nCreating a Map\nLocalization and Mapping\nPose Graph SLAM\nComplementary filter"
  },
  {
    "objectID": "06_localization.html#localization",
    "href": "06_localization.html#localization",
    "title": "06_localization",
    "section": "Localization",
    "text": "Localization\n\n\n\nGPS makes outdoor localization easy; unfortunately GPS is far from perfect.\n\nrelies on very weak radio signals received from distant orbiting satellites.\nGPS cannot work where there is no line of sight radio reception.\n\nGPS has only been in use since 1995 yet humankind has been navigating the planet for many thousands of years!\nDead reckoning is the estimation of location based on estimated speed, direction and time of travel w.r.t. a previous estimate.\n\n\n\n\n\n\n\nGiven average compass heading over the previous hour and a distance traveled the position at 33 p.m. can be found using elementary geometry from the position at 22 p.m.\n\nMeasurements on which the update is based are subject to both systematic and random error.\nModern instruments are quite precise but 500 years ago clocks, compasses and speed measurements were primitive."
  },
  {
    "objectID": "06_localization.html#localization-1",
    "href": "06_localization.html#localization-1",
    "title": "06_localization",
    "section": "Localization",
    "text": "Localization\n\n\n\nEstimates are recursive: each estimate is based on the previous one.\n\nerrors will accumulate over time\nfor sea voyages of many-years this approach was quite inadequate!\n\nThe Phonecians were navigating at sea more than 4,0004,000 years ago and they did not even have a compass!\n\n\n\n\n\n\n\nThey navigated with crude dead reckoning but wherever possible they used additional information to correct their position estimate.\n\nsightings of islands and headlands\nprimitive maps and observations of the Sun and the Pole Star.\n\n\n\n\n\n\n\nA landmark is a visible feature in the environment whose location is known w.r.t. some coordinate frame.\n\nA precise bearing measurement to two landmarks will therefore pinpoint our location, a process known as resectioning."
  },
  {
    "objectID": "06_localization.html#localization-2",
    "href": "06_localization.html#localization-2",
    "title": "06_localization",
    "section": "Localization",
    "text": "Localization\n\n\n\nThis process is critically reliant on correctly associating the observed landmark with the feature on the map.\n\nMistaking one lighthouse for another, e.g.Â ğ‚\\bm{C} for ğ\\bm{B} leads to significant error in estimated position (ğª\\bm{q} instead of ğ©\\bm{p}).\n\nThis is a very common error and countless ships have foundered because of this fundamental data association error.\n\nThis is why lighthouses flash with a unique flashing pattern!\n\n\n\n\n\n\n\n\n\n\nLocalization Problem\n\n\nFind an estimate ğ±Ì‚\\hat{\\bm{x}} of the true, but unknown position, ğ±\\bm{x} of the robot. We also wish to know the uncertainty of the estimate (standard deviation associated with the position estimate ğ±Ì‚\\hat{\\bm{x}}).\n\n\n\n\nIt is useful to describe a robotâ€™s estimated position in terms of a pdf.\n\nallows for multiple hypotheses about the robotâ€™s position."
  },
  {
    "objectID": "06_localization.html#dead-reckoning-1",
    "href": "06_localization.html#dead-reckoning-1",
    "title": "06_localization",
    "section": "Dead reckoning",
    "text": "Dead reckoning\n\nAn odometer is a sensor that measures distance traveled and sometimes also change in heading direction.\n\nFor wheeled devices, can be determined by measuring the angular rotation of the wheels.\nDirection of travel can be measured using a compass or\nChange in heading can be measured using a gyroscope.\n\nThese sensors are imperfect due to systematic errors\n\nincorrect wheel radius,\ngyroscope bias\n\nThey are also imperfect due to random errors such as slip between wheels and the ground.\nRobots w/o wheels, such as aerial robots, can use visual odometry based on observations of the world moving past the robot."
  },
  {
    "objectID": "06_localization.html#modeling-the-vehicle",
    "href": "06_localization.html#modeling-the-vehicle",
    "title": "06_localization",
    "section": "Modeling the vehicle",
    "text": "Modeling the vehicle\n\nThe first step in estimating the robotâ€™s pose is to write a function, ğŸ(â‹…)\\bm{f}(\\cdot), that describes how the vehicleâ€™s configuration changes from one time step to the next.\nThe initial pose is represented in ğ’ğ„(2)\\bm{SE}(2) as Î¾âŸ¨kâŸ©âˆ¼(cosÎ¸âŸ¨kâŸ©âˆ’sinÎ¸âŸ¨kâŸ©xâŸ¨kâŸ©sinÎ¸âŸ¨kâŸ©cosÎ¸âŸ¨kâŸ©yâŸ¨kâŸ©001)\n\\xi\\langle k \\rangle \\sim\n\\begin{pmatrix}\n\\cos{\\theta\\langle k \\rangle} & -\\sin{\\theta\\langle k \\rangle} & x\\langle k\n\\rangle \\\\ \n\\sin{\\theta\\langle k \\rangle} & \\cos{\\theta\\langle k \\rangle} & y\\langle k\n\\rangle \\\\ \n0 & 0 & 1\n\\end{pmatrix}\n\nMove forward in the vehicle xx-direction by Î´d\\delta_d and then rotate by Î´Î¸\\delta_\\theta giving the new configuration Î¾âŸ¨kâŸ©âˆ¼(cosÎ¸âŸ¨kâŸ©âˆ’sinÎ¸âŸ¨kâŸ©xâŸ¨kâŸ©sinÎ¸âŸ¨kâŸ©cosÎ¸âŸ¨kâŸ©yâŸ¨kâŸ©001)(10Î´d010001)(cosÎ´Î¸âˆ’sinÎ´Î¸0sinÎ´Î¸cosÎ´Î¸0001)âˆ¼(cos(Î¸âŸ¨kâŸ©+Î´Î¸)âˆ’sin(Î¸âŸ¨kâŸ©+Î´Î¸)xâŸ¨kâŸ©+Î´dcosÎ¸âŸ¨kâŸ©sin(Î¸âŸ¨kâŸ©+Î´Î¸)cos(Î¸âŸ¨kâŸ©+Î´Î¸)yâŸ¨kâŸ©+Î´dsinÎ¸âŸ¨kâŸ©001)\n\\begin{aligned}\n\\xi\\langle k \\rangle &\\sim\n\\begin{pmatrix}\n\\cos{\\theta\\langle k \\rangle} & -\\sin{\\theta\\langle k \\rangle} & x\\langle k\n\\rangle \\\\ \n\\sin{\\theta\\langle k \\rangle} & \\cos{\\theta\\langle k \\rangle} & y\\langle k\n\\rangle \\\\ \n0 & 0 & 1\n\\end{pmatrix}\n\\begin{pmatrix}\n1 & 0 & \\delta_d \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1\n\\end{pmatrix}\n\\begin{pmatrix}\n\\cos{\\delta_\\theta} & -\\sin{\\delta_\\theta} & 0 \\\\\n\\sin{\\delta_\\theta} & \\cos{\\delta_\\theta} & 0 \\\\ \n0 & 0 & 1\n\\end{pmatrix} \\\\ \n&\\sim\n\\begin{pmatrix}\n\\cos{\\left(\\theta \\langle k \\rangle + \\delta_\\theta\\right)} &\n-\\sin{\\left(\\theta\\langle k \\rangle + \\delta_\\theta\\right)} & \nx\\langle k \\rangle + \\delta_d \\cos{\\theta\\langle k \\rangle} \\\\\n\\sin{\\left(\\theta \\langle k \\rangle + \\delta_\\theta\\right)} &\n\\cos{\\left(\\theta\\langle k \\rangle + \\delta_\\theta\\right)} & \ny\\langle k \\rangle + \\delta_d \\sin{\\theta\\langle k \\rangle} \\\\\n0 & 0 & 1\n\\end{pmatrix}\n\\end{aligned}"
  },
  {
    "objectID": "06_localization.html#modeling-the-vehicle-1",
    "href": "06_localization.html#modeling-the-vehicle-1",
    "title": "06_localization",
    "section": "Modeling the vehicle",
    "text": "Modeling the vehicle\n\nLetâ€™s represent this succinctly as a 33-vector ğ±=(x,y,Î¸)\\bm{x} = (x, y, \\theta) so that ğ±âŸ¨k+1âŸ©=(xâŸ¨kâŸ©+Î´dcosÎ¸âŸ¨kâŸ©yâŸ¨kâŸ©+Î´dcosÎ¸âŸ¨kâŸ©Î¸âŸ¨kâŸ©+Î´Î¸)\n\\bm{x}\\langle k+1 \\rangle = \\begin{pmatrix}\nx\\langle k \\rangle + \\delta_d \\cos{\\theta\\langle k \\rangle} \\\\\ny\\langle k \\rangle + \\delta_d \\cos{\\theta\\langle k \\rangle} \\\\\n\\theta\\langle k \\rangle + \\delta_\\theta\n\\end{pmatrix}\n which gives the new configuration in terms of the previous configuration and the odometry.\nOdometry is not perfect and we model the error by imagining a random number generator (vd,vÎ¸)(v_d, v_\\theta) that corrupts the output of a perfect odometer (sensor noise).\n\n\n\n\nRobotâ€™s configuration at the next time step, including odometry error\n\n\nğ±âŸ¨k+1âŸ©=ğŸ(ğ±âŸ¨kâŸ©,Î´âŸ¨kâŸ©,ğ¯âŸ¨kâŸ©)=(xâŸ¨kâŸ©+(Î´d+vd)cosÎ¸âŸ¨kâŸ©yâŸ¨kâŸ©+(Î´d+vd)cosÎ¸âŸ¨kâŸ©Î¸âŸ¨kâŸ©+Î´Î¸+vÎ¸)\n\\bm{x}\\langle k+1 \\rangle = \\bm{f}\\left( \\bm{x}\\langle k \\rangle, \\delta \\langle\nk \\rangle, \\bm{v}\\langle k \\rangle \\right) = \\begin{pmatrix}\nx\\langle k \\rangle + (\\delta_d+v_d) \\cos{\\theta\\langle k \\rangle} \\\\\ny\\langle k \\rangle + (\\delta_d+v_d) \\cos{\\theta\\langle k \\rangle} \\\\\n\\theta\\langle k \\rangle + \\delta_\\theta + v_\\theta\n\\end{pmatrix}\n\n\n\n\n\nWe typically model the odometry noise as ğ¯=(vd,vÎ¸)âŠ¤âˆ¼ğ’©(0,ğ•)\\bm{v} = \\left(v_d, v_\\theta\\right)^\\top \\sim \\mathcal{N}(0, \\bm{V}), a zero-mean multivariate Gaussian, with variance ğ•=diag{Ïƒd2,ÏƒÎ¸2}\\bm{V} = \\text{diag}\\left\\{\\sigma_d^2, \\sigma_\\theta^2 \\right\\}."
  },
  {
    "objectID": "06_localization.html#estimating-pose",
    "href": "06_localization.html#estimating-pose",
    "title": "06_localization",
    "section": "Estimating pose",
    "text": "Estimating pose\n\n\n\nShipâ€™s navigator problem\n\n\nHow to estimate our new pose given the previous pose and noise odometry?\n\n\n\n\nThe mathematical tool that we will use is the Kalman filter.\n\nprovides the optimal estimate of the system state assuming zero-mean Gaussian noise.\n\nThe filter is a recursive algorithm that updates, at each time step, the optimal estimate of the unknown true configuration and the uncertainty associated with that estimate.\nThe Kalman filter is formulated for linear systems but our model of the vehicleâ€™s motion is nonlinear, so weâ€™ll use the extended Kalman filter (EKF).\nFor this problem, the state vector is the vehicleâ€™s configuration ğ±=(xv,yv,Î¸v) \\bm{x} =\n\\left(x_v, y_v, \\theta_v \\right)  and the prediction equations ğ±Ì‚+âŸ¨k+1âŸ©=ğŸ(ğ±Ì‚âŸ¨kâŸ©,ğ®Ì‚âŸ¨kâŸ©)ğÌ‚+âŸ¨k+1âŸ©=ğ…xğÌ‚âŸ¨kâŸ©ğ…xâŠ¤+ğ…vğ•Ì‚ğ…vâŠ¤\n\\begin{aligned}\n\\hat{\\bm{x}}^+\\langle k+1 \\rangle &= \\bm{f}\\left(\\hat{\\bm{x}}\\langle k \\rangle,\n\\hat{\\bm{u}}\\langle k \\rangle \\right) \\\\\n\\hat{\\bm{P}}^+\\langle k+1 \\rangle &= \\bm{F}_x\\hat{\\bm{P}}\\langle k\n\\rangle \\bm{F}_x^\\top + \\bm{F}_v \\hat{\\bm{V}}\\bm{F}_v^\\top\n\\end{aligned}\n describe how the state and covariance evolve with time."
  },
  {
    "objectID": "06_localization.html#estimating-pose-1",
    "href": "06_localization.html#estimating-pose-1",
    "title": "06_localization",
    "section": "Estimating pose",
    "text": "Estimating pose\nğ±Ì‚+âŸ¨k+1âŸ©=ğŸ(ğ±Ì‚âŸ¨kâŸ©,ğ®Ì‚âŸ¨kâŸ©)ğÌ‚+âŸ¨k+1âŸ©=ğ…xğÌ‚âŸ¨kâŸ©ğ…xâŠ¤+ğ…vğ•Ì‚ğ…vâŠ¤\n\\begin{aligned}\n\\hat{\\bm{x}}^+\\langle k+1 \\rangle &= \\bm{f}\\left(\\hat{\\bm{x}}\\langle k \\rangle,\n\\hat{\\bm{u}}\\langle k \\rangle \\right) \\\\\n\\hat{\\bm{P}}^+\\langle k+1 \\rangle &= \\bm{F}_x\\hat{\\bm{P}}\\langle k\n\\rangle \\bm{F}_x^\\top + \\bm{F}_v \\hat{\\bm{V}}\\bm{F}_v^\\top\n\\end{aligned}\n\n\nğ®Ì‚âŸ¨kâŸ©\\hat{\\bm{u}}\\langle k \\rangle: input to the process; in this case is the measured odometry, so ğ®Ì‚âŸ¨kâŸ©=Î´âŸ¨kâŸ©\\hat{\\bm{u}}\\langle k \\rangle = \\delta \\langle k \\rangle.\nğÌ‚âˆˆâ„3Ã—3\\hat{\\bm{P}} \\in \\mathbb{R}^{3 \\times 3} is a covariance matrix representing the uncertainty in the estimated vehicle configuration.\nğ•Ì‚\\hat{\\bm{V}} is our estimate of the covariance of the odometry noise, which in reality, we do not know.\nğ…x\\bm{F}_x and ğ…v\\bm{F}_v are Jacobian matrices obtained by differentiating the equations of motion and evaluating the result at ğ¯=0\\bm{v} = 0, giving ğ…x=âˆ‚ğŸâˆ‚ğ±|ğ¯=0=(10âˆ’Î´dsinÎ¸v01Î´dcosÎ¸v001)ğ…v=âˆ‚ğŸâˆ‚ğ¯|ğ¯=0=(cosÎ¸v0sinÎ¸v001)\n\\begin{aligned}\n\\bm{F}_x &= \\frac{\\partial \\bm{f}}{\\partial \\bm{x}}\\vert_{\\bm{v}=0} =\n\\begin{pmatrix}\n1 & 0 & -\\delta_d \\sin{\\theta_v} \\\\ 0 & 1 & \\delta_d \\cos{\\theta_v} \\\\ 0 & 0 & 1\n\\end{pmatrix} \\\\\n\\bm{F}_v &= \\frac{\\partial \\bm{f}}{\\partial \\bm{v}}\\vert_{\\bm{v}=0} = \n\\begin{pmatrix}\n\\cos{\\theta_v} & 0 \\\\ \\sin{\\theta_v} & 0 \\\\ 0 & 1\n\\end{pmatrix}\n\\end{aligned}\n which are functions of the current state and odometry."
  },
  {
    "objectID": "06_localization.html#estimating-pose-2",
    "href": "06_localization.html#estimating-pose-2",
    "title": "06_localization",
    "section": "Estimating pose",
    "text": "Estimating pose\n\n\n\nThe true (blue) and estimated (red) robot path is shown in the figure to the right.\n\n95%95\\% confidence ellipses are indicated in green.\nThat is there is 95%95\\% chance that the robotâ€™s xx- and yy-coordinate is within Â±2Ïƒ\\pm 2\\sigma bound.\n\nThere are off-diagonal terms in the correlation matrix, which indicate that the uncertainties between the corresponding variables are related.\n\nFor example, the value P1,3=P3,1=âˆ’0.5575P_{1,3}=P_{3,1} = -0.5575 indicats the uncertainties in xx and Î¸\\theta are related.\n\nThe total uncertainty is given by det(ğÌ‚)\\sqrt{\\det{(\\hat{\\bm{P}})}} and is plotted.\n\nIt never decreases because RHS of the ğÌ‚\\hat{\\bm{P}} eqn. is positive definite.\nMeans that ğ\\bm{P}, the position uncertainty can never decrease!"
  },
  {
    "objectID": "06_localization.html#localizing-with-a-map-1",
    "href": "06_localization.html#localizing-with-a-map-1",
    "title": "06_localization",
    "section": "Localizing with a map",
    "text": "Localizing with a map\n\nRecall: uncertainty in position grows without bound using dead-reckoning alone.\nThe solution, as the Phoenicians worked out 4,0004,000 years ago, is to bring in additional information from observations of known features in the world.\n\nIn the examples, we will use a map that contains NN fixed but randomly located landmarks whose positions are known.\n\nThe robot is equipped with a sensor that provides observations of the landmarks w.r.t. the robot, described by ğ³=ğ¡(ğ±,ğ©i), \\bm{z} = \\bm{h}(\\bm{x}, \\bm{p}_i),  where ğ©i=(xi,yi)âŠ¤\\bm{p}_i = \\left(x_i, y_i\\right)^\\top is the known location of the ithi^{\\text{th}} landmark in the world frame.\nTo make this concrete, letâ€™s consider a common type of sensor that measures the range and bearing angle to a landmark in the environment\n\nsuch as radar or a scanning-laser rangefinder.\n\n\n\n\n\nObservation of the ithi^{\\text{th}} landmark\n\n\nğ³=ğ¡(ğ±,ğ©i)=((yiâˆ’yv)2+(xiâˆ’xv)2arctan(yiâˆ’yv,xiâˆ’xv)âˆ’Î¸v)+(wrwÎ²)\n\\bm{z} = \\bm{h}(\\bm{x}, \\bm{p}_i) = \n\\begin{pmatrix}\n\\sqrt{ \\left(y_i - y_v \\right)^2 + \\left(x_i - x_v\\right)^2 } \\\\ \n\\arctan{\\left(y_i-y_v, x_i-x_v\\right)} - \\theta_v\n\\end{pmatrix} + \n\\begin{pmatrix} w_r \\\\ w_\\beta \\end{pmatrix}"
  },
  {
    "objectID": "06_localization.html#localizing-with-a-map-2",
    "href": "06_localization.html#localizing-with-a-map-2",
    "title": "06_localization",
    "section": "Localizing with a map",
    "text": "Localizing with a map\n\n\n\nObservation of the ithi^{\\text{th}} landmark\n\n\nğ³=ğ¡(ğ±,ğ©i)=((yiâˆ’yv)2+(xiâˆ’xv)2arctan(yiâˆ’yv,xiâˆ’xv)âˆ’Î¸v)+(wrwÎ²)\n\\bm{z} = \\bm{h}(\\bm{x}, \\bm{p}_i) = \n\\begin{pmatrix}\n\\sqrt{ \\left(y_i - y_v \\right)^2 + \\left(x_i - x_v\\right)^2 } \\\\ \n\\arctan{\\left(y_i-y_v, x_i-x_v\\right)} - \\theta_v\n\\end{pmatrix} + \n\\begin{pmatrix} w_r \\\\ w_\\beta \\end{pmatrix}\n\n\n\n\n\nğ³=(r,Î²)âŠ¤\\bm{z} = (r, \\beta)^\\top, rr is the range, Î²\\beta is the bearing angle.\nğ°=(wr,wÎ²)âŠ¤âˆ¼ğ’©(0,ğ–),ğ–=diag{Ïƒr2,ÏƒÎ²2}\\bm{w} = \\left(w_r, w_\\beta\\right)^\\top \\sim \\mathcal{N}(0, \\bm{W}), \\;\\; \\bm{W} = \\text{diag}\\{ \\sigma_r^2, \\sigma_\\beta^2 \\}: constant covariance matrix.\nIn implementation, this sensor return the range and bearing to some landmark along with its identity (to avoid data association problem).\n\nRecall: the location (xi,yi)(x_i, y_i) of the measured landmark is known in the world frame.\n\nUsing the equation above, the robot can estimate the range and bearing angle to the landmark based on its own estimated position and the known position of the landmark from the map.\nAny difference between the observation ğ³â™¯\\bm{z}^\\sharp and the estimated observation indicates an error in the robotâ€™s pose estimate ğ±Ì‚\\hat{\\bm{x}} â€“ it isnâ€™t where it thought it was!"
  },
  {
    "objectID": "06_localization.html#localizing-with-a-map-3",
    "href": "06_localization.html#localizing-with-a-map-3",
    "title": "06_localization",
    "section": "Localizing with a map",
    "text": "Localizing with a map\n\nThis difference\n\n\n\n\nObservation error\n\n\nğ›=ğ³â™¯âŸ¨k+1âŸ©âˆ’ğ¡(ğ±Ì‚âŸ¨k+1âŸ©,ğ©i)\n\\bm{\\nu} = \\bm{z}^\\sharp \\langle k+1 \\rangle - \\bm{h}\\left(\\hat{{\\bm{x}}} \n\\langle k + 1 \\rangle, \\bm{p}_i \\right)\n\n\n\n\nis key to the operation of the Kalman filter.\n\nIt is called the innovation since it represents new information.\nKalman filter uses the innovation to correct the state estimate and update the uncertainty estimate in an optimal way.\nThe predicted state, computed earlier, is updated by\n\n\n\n\nKalman filter update equations\n\n\nğ±Ì‚âŸ¨k+1âŸ©=ğ±Ì‚+âŸ¨k+1âŸ©+ğŠğ›ğÌ‚âŸ¨k+1âŸ©=ğÌ‚+âŸ¨k+1âŸ©âˆ’ğŠğ‡xğÌ‚+âŸ¨k+1âŸ©\n\\begin{aligned}\n\\hat{\\bm{x}} \\langle k+1 \\rangle &= \\hat{\\bm{x}}^+ \\langle k+1 \\rangle +\n\\bm{K}\\bm{\\nu} \\\\\n\\hat{\\bm{P}} \\langle k+1 \\rangle &= \\hat{\\bm{P}}^+ \\langle k+1 \\rangle -\n\\bm{K}\\bm{H}_x\\hat{\\bm{P}}^+ \\langle k+1 \\rangle\n\\end{aligned}"
  },
  {
    "objectID": "06_localization.html#localizing-with-a-map-4",
    "href": "06_localization.html#localizing-with-a-map-4",
    "title": "06_localization",
    "section": "Localizing with a map",
    "text": "Localizing with a map\n\n\n\nKalman filter update equations\n\n\nğ±Ì‚âŸ¨k+1âŸ©=ğ±Ì‚+âŸ¨k+1âŸ©+ğŠğ›ğÌ‚âŸ¨k+1âŸ©=ğÌ‚+âŸ¨k+1âŸ©âˆ’ğŠğ‡xğÌ‚+âŸ¨k+1âŸ©\n\\begin{aligned}\n\\hat{\\bm{x}} \\langle k+1 \\rangle &= \\hat{\\bm{x}}^+ \\langle k+1 \\rangle +\n\\bm{K}\\bm{\\nu} \\\\\n\\hat{\\bm{P}} \\langle k+1 \\rangle &= \\hat{\\bm{P}}^+ \\langle k+1 \\rangle -\n\\bm{K}\\bm{H}_x\\hat{\\bm{P}}^+ \\langle k+1 \\rangle\n\\end{aligned}\n\n\n\n\n\nThese take the predicted values for the next tiem step, denoted with the +{~}^+ and compute the optimal estimate by applying landmark measurement from step k+1k+1.\n\n\n\n\nKalman gain\n\n\nğŠ=ğ+âŸ¨k+1âŸ©ğ‡xâŠ¤ğ’âˆ’1ğ’=ğ‡xğ+âŸ¨k+1âŸ©ğ‡xâŠ¤+ğ‡wğ–Ì‚ğ‡wâŠ¤\n\\begin{aligned}\n\\bm{K} &= \\bm{P}^+ \\langle k+1 \\rangle \\bm{H}_x^\\top \\bm{S}^{-1} \\\\\n\\bm{S} &= \\bm{H}_x \\bm{P}^+ \\langle k+1 \\rangle \\bm{H}_x^\\top + \\bm{H}_w\n\\hat{\\bm{W}} \\bm{H}_w^\\top\n\\end{aligned}\n\n\n\n\nwhere ğ–Ì‚\\hat{\\bm{W}} is the estimated covariance of the sensor noise and ğ‡x\\bm{H}_x and ğ‡w\\bm{H}_w are Jacobians\nğ‡x=âˆ‚ğ¡âˆ‚ğ±|ğ°=0=(âˆ’1r(xiâˆ’xv)âˆ’1r(yiâˆ’yv)01r(yiâˆ’yv)âˆ’1r(xiâˆ’xv)âˆ’1),ğ‡w=âˆ‚ğ¡âˆ‚ğ°|ğ°=0=(1001).\n\\bm{H}_x = \\frac{\\partial \\bm{h}}{\\partial \\bm{x}}\\vert_{\\bm{w}=0} = \n\\begin{pmatrix}\n-\\frac{1}{r}\\left(x_i - x_v\\right) & -\\frac{1}{r}\\left(y_i - y_v\\right) & 0 \\\\\n\\frac{1}{r}\\left(y_i - y_v\\right) & -\\frac{1}{r}\\left(x_i - x_v\\right) & -1\n\\end{pmatrix}, \\quad\\quad\n\\bm{H}_w = \\frac{\\partial \\bm{h}}{\\partial \\bm{w}}\\vert_{\\bm{w}=0} = \n\\begin{pmatrix}\n1 & 0 \\\\ 0 & 1\n\\end{pmatrix}."
  },
  {
    "objectID": "06_localization.html#localizing-with-a-map-5",
    "href": "06_localization.html#localizing-with-a-map-5",
    "title": "06_localization",
    "section": "Localizing with a map",
    "text": "Localizing with a map\n\n\nÂ \n\nThe Kalman gain matrix ğŠ\\bm{K} distributes the innovation from the landmark observation, a 22-vector, to update every element of the state vector.\nNote that the second term in the covariance update equation is subtracted from the estimated covariance.\n\nThis provides a means for estimated covariance to decrease, which was not possible for the dead-reckoning case."
  },
  {
    "objectID": "06_localization.html#localizing-with-a-map-6",
    "href": "06_localization.html#localizing-with-a-map-6",
    "title": "06_localization",
    "section": "Localizing with a map",
    "text": "Localizing with a map\n\n\n\nEKF localization\n\nBlue: true path of the robot,\nRed: estimated path from odometry and landmarks,\nStars: landmarks.\n\nThe error ellipses are now much smaller â€“ many can hardly be seen.\nThe bottom figure shows a zoomed view of the robotâ€™s actual and estimated path (moving from top to bottom).\n\nThe error ellipses grow as the robot moves and then shrinks just after a jag in the estimated path.\nThis corresponds to the observation of a landmark.\nNew information, beyond odometry, has been used to correct the state in the Kalman filter update phase."
  },
  {
    "objectID": "06_localization.html#localizing-with-a-map-7",
    "href": "06_localization.html#localizing-with-a-map-7",
    "title": "06_localization",
    "section": "Localizing with a map",
    "text": "Localizing with a map\n\n\n\nOverall uncertainty is no longer growing monotonically\n\nWhen the robot sees a landmark, it is able to dramatically reduce its estimated covariance.\n\nThe bottom figure shows the error associated with each component of pose\n\nThe pink background is estimated 95%95\\% confidence bound (derived from the covariance matrix).\nNotice the error is mostly within this envelope.\n\nBelow this is plotted the landmark observations\n\nNotice that the confidence bounds are tight (indicating low uncertainty) while landmarks are being observed.\nThey start to grow once observations stop.\nAs soon as an observation is made the uncertainty rapidly decreases."
  },
  {
    "objectID": "06_localization.html#creating-a-map-1",
    "href": "06_localization.html#creating-a-map-1",
    "title": "06_localization",
    "section": "Creating a map",
    "text": "Creating a map\n\nSomebody or something has to create the maps we will use.\n\n\n\n\nAssumptions:\n\n\n\nSensor can determine the identity of each observed landmark.\nThe robot knows its own position perfectly (ideal localization).\n\n\n\n\n\nWe need to estimate the coordinates of the landmarks so for this problem, the state vector comprises the estimated coordinates of the MM landmarks we have observed so far: ğ±Ì‚=(x1,y1,x2,y2,â€¦,xM,yM)âˆˆâ„2MÃ—1. \\hat{\\bm{x}} = \\left(x_1, y_1, x_2, y_2, \\ldots, x_M, y_M \\right)\n\\in \\mathbb{R}^{2M \\times 1}. \nThe corresponding estimated covariance ğÌ‚\\hat{\\bm{P}} will be a 2MÃ—2M2M \\times 2M matrix.\nThe state vector has variable length since we do now know in advance how many landmarks exist.\n\nInitially M=0M = 0 and is incremented every time a previously unseen landmark is observed."
  },
  {
    "objectID": "06_localization.html#creating-a-map-2",
    "href": "06_localization.html#creating-a-map-2",
    "title": "06_localization",
    "section": "Creating a map",
    "text": "Creating a map\n\nThe prediction equation is straightforward since the landmarks are stationary. ğ±Ì‚âŸ¨k+1âŸ©=ğ±Ì‚âŸ¨kâŸ©ğÌ‚+âŸ¨k+1âŸ©=ğÌ‚âŸ¨kâŸ©\n\\begin{aligned}\n\\hat{\\bm{x}} \\langle k+1 \\rangle &= \\hat{\\bm{x}} \\langle k \\rangle \\\\\n\\hat{\\bm{P}}^+ \\langle k+1 \\rangle &= \\hat{\\bm{P}} \\langle k \\rangle\n\\end{aligned}\n\nWe introduce the function ğ (â‹…)\\bm{g}(\\cdot), the inverse of ğ¡(â‹…)\\bm{h}(\\cdot), which gives the coordinates of the observed landmark based on the known vehicle pose and the sensor observation ğ (ğ±,ğ³)=(xv+rcos(Î¸v+Î²)yv+rsin(Î¸v+Î²)) \\bm{g}(\\bm{x}, \\bm{z}) = \\begin{pmatrix}\nx_v + r \\cos{\\left(\\theta_v + \\beta\\right)} \\\\\ny_v + r \\sin{\\left(\\theta_v + \\beta\\right)}\n\\end{pmatrix} \nSince ğ±Ì‚\\hat{\\bm{x}} has a variable length, we need to extend the state vector and the covariance matrix whenever we encounter a previously unseen landmark. ğ±âŸ¨kâŸ©â€²=ğ²(ğ±âŸ¨kâŸ©,ğ±vâŸ¨kâŸ©)=(ğ±âŸ¨kâŸ©ğ (ğ±vâŸ¨kâŸ©,ğ³âŸ¨kâŸ©)). \n\\bm{x} \\langle k \\rangle^\\prime = \\bm{y}\\left(\\bm{x} \\langle k \\rangle,\n\\bm{x}_v \\langle k \\rangle \\right) \n= \\begin{pmatrix}\n\\bm{x} \\langle k \\rangle \\\\\n\\bm{g} \\left(\\bm{x}_v \\langle k \\rangle, \\bm{z} \\langle k \\rangle \\right)\n\\end{pmatrix}.\n\n\nThis appends the sensor-based estimate of the new landmarkâ€™s coordinates to those already in the map.\nThe order of feature coordinates within ğ±Ì‚\\hat{\\bm{x}} therefore depends on the order in which they are observed."
  },
  {
    "objectID": "06_localization.html#creating-a-map-3",
    "href": "06_localization.html#creating-a-map-3",
    "title": "06_localization",
    "section": "Creating a map",
    "text": "Creating a map\n\nThe covariance matrix also needs to be extended when a new landmark is observed and this is achieved by ğÌ‚âŸ¨kâŸ©â€²=ğ˜z(ğÌ‚âŸ¨kâŸ©00ğ–Ì‚)ğ˜zâŠ¤ \\hat{\\bm{P}} \\langle k \\rangle^\\prime = \\bm{Y}_z \\begin{pmatrix}\n\\hat{\\bm{P}}\\langle k \\rangle & 0 \\\\ 0 & \\hat{\\bm{W}} \\end{pmatrix}\n\\bm{Y}_z^\\top  where ğ˜z\\bm{Y}_z is the insertion Jacobian ğ˜z=âˆ‚ğ²âˆ‚ğ³=(ğˆnÃ—n0nÃ—2ğ†x02Ã—nâˆ’3ğ†z) \\bm{Y}_z =\n\\frac{\\partial \\bm{y}}{\\partial \\bm{z}} = \\begin{pmatrix} \\bm{I}_{n \\times n} &\n& \\bm{0}_{n \\times 2} \\\\ \\bm{G}_x & \\bm{0}_{2 \\times n-3} & \\bm{G}_z\n\\end{pmatrix}  that relates the rate of change of the extended state vector to the new observation.\nnn is the dimension of ğÌ‚\\hat{\\bm{P}} prior to being extended and ğ†x=âˆ‚ğ âˆ‚ğ±=(000000),ğ†z=âˆ‚ğ âˆ‚ğ³=(cos(Î¸v+Î²)âˆ’rsin(Î¸v+Î²)sin(Î¸v+Î²)rcos(Î¸v+Î²))\n\\bm{G}_x = \\frac{\\partial \\bm{g}}{\\partial \\bm{x}} = \\begin{pmatrix} 0 & 0 & 0\n\\\\ 0 & 0 & 0 \\end{pmatrix}, \\quad\\quad\n\\bm{G}_z = \\frac{\\partial \\bm{g}}{\\partial \\bm{z}} = \\begin{pmatrix} \n\\cos{\\left(\\theta_v + \\beta\\right)} & -r\\sin{\\left(\\theta_v + \\beta\\right)} \\\\\n\\sin{\\left(\\theta_v + \\beta\\right)} & r\\cos{\\left(\\theta_v + \\beta\\right)}\n\\end{pmatrix}\n\nAn additional Jacobian that we will need later is the Jacobian for ğ¡(â‹…)\\bm{h}(\\cdot) ğ‡pi=âˆ‚ğ¡âˆ‚ğ©i=(1r(xiâˆ’xv)1r(yiâˆ’yv)âˆ’1r2(yiâˆ’yv)1r2(xiâˆ’xv)). \\bm{H}_{p_i} = \\frac{\\partial \\bm{h}}{\\partial \\bm{p}_i} = \\begin{pmatrix} \n\\frac{1}{r}\\left(x_i - x_v\\right) & \\frac{1}{r}\\left(y_i - y_v\\right) \\\\\n-\\frac{1}{r^2}\\left(y_i - y_v\\right) & \\frac{1}{r^2}\\left(x_i - x_v\\right)\n\\end{pmatrix}."
  },
  {
    "objectID": "06_localization.html#creating-a-map-4",
    "href": "06_localization.html#creating-a-map-4",
    "title": "06_localization",
    "section": "Creating a map",
    "text": "Creating a map\n\n\n\n\n\n\nEKF mapping results\n\n\nThe estimated landmarks are indicated by black dots with 95%95\\% confidence ellipses (green, hard to see w/o zooming), the true location (black star marker) and the robotâ€™s path (blue). The landmark estimates have not fully converged to their true values."
  },
  {
    "objectID": "06_localization.html#simultaneous-localization-and-mapping",
    "href": "06_localization.html#simultaneous-localization-and-mapping",
    "title": "06_localization",
    "section": "Simultaneous localization and mapping",
    "text": "Simultaneous localization and mapping\n\nFeels like a â€˜â€™chicken and eggâ€™â€™ problem\n\nwe need a map to localize and\nwe need to localize to make a map.\n\nHowever, based on what we have learned so far this problem is now quite straightforward to solve.\nThe state vector comprises the vehicle configuration and the coordinates of the MM landmarks that have been observed so far ğ±Ì‚=(xv,yv,Î¸v,x1,y1,x2,y2,â€¦,xM,yM)âŠ¤âˆˆâ„2M+3Ã—1 \\hat{\\bm{x}} =\n\\left(x_v, y_v, \\theta_v, x_1, y_1, x_2, y_2, \\ldots, x_M, y_M \\right)^\\top \\in\n\\mathbb{R}^{2M+3 \\times 1} \nThe estimated covariance is a (2M+3)Ã—(2M+3)(2M+3) \\times (2M+3) matrix and has the structure ğÌ‚=(ğÌ‚vvğÌ‚vmğÌ‚vmâŠ¤ğÌ‚mm) \\hat{\\bm{P}} = \\begin{pmatrix} \\hat{\\bm{P}}_{vv} &\n\\hat{\\bm{P}}_{vm} \\\\ \\hat{\\bm{P}}_{vm}^\\top & \\hat{\\bm{P}}_{mm} \\end{pmatrix}  where ğÌ‚vv\\hat{\\bm{P}}_{vv} is the covariance of the vehicle pose, ğÌ‚mm\\hat{\\bm{P}}_{mm} the covariance of the map landmark positions, and ğÌ‚vm\\hat{\\bm{P}}_{vm} is the correlation between vehicle landmark states."
  },
  {
    "objectID": "06_localization.html#slam",
    "href": "06_localization.html#slam",
    "title": "06_localization",
    "section": "SLAM",
    "text": "SLAM\n\nThe predicted vehicle state and covariances are as they were given in localization section with perfect map knowledge.\nWhen a new feature is observed the state vector is updated using the insertion Jacobian ğ˜z\\bm{Y}_z but in this case ğ†x\\bm{G}_x is nonzero ğ†x=âˆ‚ğ âˆ‚ğ±=(10âˆ’rsin(Î¸v+Î²)01rcos(Î¸v+Î²)) \\bm{G}_x = \\frac{\\partial \\bm{g}}{\\partial \\bm{x}} = \\begin{pmatrix} \n1 & 0 & -r \\sin{\\left(\\theta_v + \\beta\\right)} \\\\\n0 & 1 & r \\cos{\\left(\\theta_v + \\beta\\right)} \\end{pmatrix}  since the estimate of the new landmark depends on the state vector which now contains the vehicleâ€™s pose.\nFor SLAM, the Jacobian ğ‡x\\bm{H}_x describes how the landmark observation changes w.r.t. the state vector. The observation will depend on the position of the vehicle and on the position of the observed landmark ğ‡x=âˆ‚ğ¡âˆ‚ğ±|w=0=(ğ‡xvâ‹¯0â‹¯ğ‡piâ‹¯0)âˆˆâ„2Ã—(2M+3). \\bm{H}_x =\n\\frac{\\partial \\bm{h}}{\\partial \\bm{x}}\\vert_{w=0} = \\begin{pmatrix}\n\\bm{H}_{x_v} & \\cdots & 0 & \\cdots & \\bm{H}_{p_i} & \\cdots & 0 \\end{pmatrix} \\in\n\\mathbb{R}^{2 \\times \\left(2M+3\\right)}. \nNow, the Kalman gain matrix ğŠ\\bm{K} distributes innovation from the landmark observation, a 22-vector, to update every element of the state vector â€“ the pose of the vehicle and the position of every landmark in the map."
  },
  {
    "objectID": "06_localization.html#slam-results",
    "href": "06_localization.html#slam-results",
    "title": "06_localization",
    "section": "SLAM â€“ results",
    "text": "SLAM â€“ results\n\n\n\n\n\nSLAM â€“ path\n\n\nSimultaneous localization and mapping showing the true (blue) and estimated (red) robot path superimposed on the true map (black star marker). The estimated map features are indicated by black dots with 95%95\\% confidence ellipses (green).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSLAM â€“ covariance\n\n\nThe final covariance matrix is shown graphically on the right. The landmark uncertainties never increase.\nThe position prediction model is that they do not move, but they also never drop below the initial uncertainty of the vehicle.\n\n\n\n\n\n\nThe correlations are used by the Kalman filter to connect the observation of any landmark to an improvement in the estimate of every other landmark in the map as well as the vehicle pose. It is as if all the states were connected by springs."
  },
  {
    "objectID": "06_localization.html#pose-graph-slam-1",
    "href": "06_localization.html#pose-graph-slam-1",
    "title": "06_localization",
    "section": "Pose Graph SLAM",
    "text": "Pose Graph SLAM\nÂ \n\nAn alternative approach to the SLAM problem is to separate it into two components:\n\na front-end and a back-end\n\nThe robotâ€™s path is considered to be a sequence of distinct poses.\nThe task is to estimate those poses.\nConstraints between the unknown poses are based on measurements from a variety of sensors including odometry, laser scanners and cameras."
  },
  {
    "objectID": "06_localization.html#pose-graph-slam-2",
    "href": "06_localization.html#pose-graph-slam-2",
    "title": "06_localization",
    "section": "Pose Graph SLAM",
    "text": "Pose Graph SLAM\n\n\n\nThe problem is formulated as a directed graph.\nA node corresponds to a robot pose or a landmark position.\nAn edge between two nodes represents a spatial constraint between the nodes derived from some sensor data.\n\n\n\n\nDead-reckoning example\n\n\nThe robot travels around a square. By the time the robot reaches node 44, the error is significant.\nHowever, when it makes a measurement of node 11, a consraint is added â€“ the dashed edge â€“ indicating that the nodes are closer than the estimated relative pose based on the chain of relative poses from odometry: 1Î¾2â™¯âŠ•2Î¾3â™¯âŠ•3Î¾4â™¯{^1}\\xi_2^\\sharp \\oplus {^2}\\xi_3^\\sharp \\oplus {^3}\\xi_4^\\sharp.\nThe back-end algorithm will then pull all the nodes closer to their correct pose.\n\n\n\n\n\n\n\n\n\n\nPose-graph SLAM example\n\n\nPlaces are shown as circular nodes and have an associated pose.\nLandmarks are shown as star-shaped nodes and have an associated pose.\nEdges represent a measurement of a relative pose or position w.r.t. the node at the tail of the arrow."
  },
  {
    "objectID": "06_localization.html#pose-graph-slam-3",
    "href": "06_localization.html#pose-graph-slam-3",
    "title": "06_localization",
    "section": "Pose Graph SLAM",
    "text": "Pose Graph SLAM\n\n\nThe front-end adds new nodes as the robot travels as well as edges that define constraints between poses. E.g.:\n\nWhen moving from one place to another wheel odometry gives an estimate of distance and change in orientation, which is a constraint.\nThe robotâ€™s exteroceptive sensors may observe the relative position of a landmark and this also adds a constraint.\n\nEvery measurement adds a constraint â€“ an edge in the graph.\n\nThere is no limit to the number of edges entering or leaving a node.\n\n\n\nThe back-end adjusts the poses of the nodes so that the constraints are satisfied as well as possible\n\nThe sensor observations are explained optimally."
  },
  {
    "objectID": "06_localization.html#pose-graph-slam-4",
    "href": "06_localization.html#pose-graph-slam-4",
    "title": "06_localization",
    "section": "Pose Graph SLAM",
    "text": "Pose Graph SLAM\n\n\nCoordinate frames {i}\\{i\\} and {j}\\{j\\} are associated with robot poses ii and jj.\nWe seek to estimate 0Î¾i{^0}\\xi_i and 0Î¾j{^0}\\xi_j in the world coordinate frame.\n\n\nThe robot makes a measurement of the relative pose iÎ¾jâ™¯{^i}\\xi_j^\\sharp which will, in general, be different than the relative pose iÎ¾j{^i}\\xi_j inferred from poses 0Î¾i{^0}\\xi_i and 0Î¾j{^0}\\xi_j.\nThe difference, or innovation, is caused by the error in the sensor measurement iÎ¾jâ™¯{^i}\\xi_j^\\sharp and/or the node poses 0Î¾i{^0}\\xi_i and 0Î¾j{^0}\\xi_j.\n\nWe use it to adjust the poses of the nodes.\n\nThere is insufficient information to determine where the error lies\n\nNaively adjusting 0Î¾i{^0}\\xi_i and 0Î¾j{^0}\\xi_j to better explain the measurement might increase the error in another part of the graph.\nWe need to minimize the error consistently over the whole graph.\n\n\n\n\n\n\n\n\n\nPose graph notation\n\n\nThe light gray robot is the estimated pose of {j}\\{j\\} based on the sensor measurement iÎ¾jâ™¯{^i}\\xi_j^\\sharp.\nThe yellow ellipse indicates the uncertainty associated with that measurement."
  },
  {
    "objectID": "06_localization.html#pose-graph-slam-5",
    "href": "06_localization.html#pose-graph-slam-5",
    "title": "06_localization",
    "section": "Pose Graph SLAM",
    "text": "Pose Graph SLAM\n\nThe first step is to express the error associated with the graph edge in terms of the sensor measurement and our best estimates of the node poses w.r.t. the world frame Î¾Îµ=âŠ–iÎ¾jâ™¯âŠ–0Î¾Ì‚iâŠ•0Î¾Ì‚jâˆˆğ’ğ„(2) \\xi_\\varepsilon = \\ominus {^i}\\xi_j^\\sharp \\ominus\n{^0}\\hat{\\xi}_i \\oplus {^0}\\hat{\\xi}_j \\in \\bm{SE}(2)  which is ideally zero.\n\n\n\n\nWe can formulate this as a minimization problem and attempt to find the poses of all the nodes ğ±={Î¾1,Î¾2,â€¦,Î¾N}\\bm{x} = \\left\\{ \\xi_1, \\xi_2, \\ldots, \\xi_N \\right\\} that minimizes the error across all the edges ğ±*=argminğ±âˆ‘kFk(ğ±) \\bm{x}^* = \\arg \\min_\\bm{x} \\sum_k\nF_k(\\bm{x}) \n\nğ±\\bm{x} is the state of the pose graph and contains the pose of every node.\nFk(ğ±)F_k(\\bm{x}) is a nonnegative scalar cost associated with the edge kk connecting node ii to node jj.\n\n\n\n\n\n\n\nIf we convert edge pose error to a vector representation Î¾Îµâˆ¼(x,y,Î¸)=ğŸk(ğ±)\\xi_\\varepsilon \\sim (x, y, \\theta) = \\bm{f}_k(\\bm{x}) then the scalar cost can be obtained as a quadratic expression ğ…k(ğ±)=ğŸkâŠ¤ğ›€kğŸk(ğ±). \\bm{F}_k(\\bm{x}) = \\bm{f}_k^\\top \\bm{\\Omega}_k\n\\bm{f}_k(\\bm{x})."
  },
  {
    "objectID": "06_localization.html#pose-graph-slam-6",
    "href": "06_localization.html#pose-graph-slam-6",
    "title": "06_localization",
    "section": "Pose Graph SLAM",
    "text": "Pose Graph SLAM\n\n\n\nThe pose graph can also include landmarks as shown in the figure.\nLandmarks have a position ğjâˆˆâ„2\\bm{P}_j \\in \\mathbb{R}^2, not a pose, and therefore differ from the nodes discussed so far.\nTo accommodate this, we redefine the state vector ğ±={Î¾1,Î¾2,â€¦,Î¾n|ğ1,ğ2,â€¦,ğM}\\bm{x} = \\left\\{ \\xi_1, \\xi_2, \\ldots, \\xi_n \\vert \\bm{P}_1, \\bm{P}_2, \\ldots, \\bm{P}_M \\right\\}.\n\n\n\n\n\n\nThe robot at pose ii observes landmark jj at range and bearing ğ³â™¯=(râ™¯,Î²â™¯)\\bm{z}^\\sharp = \\left( r^\\sharp, \\beta^\\sharp \\right) which is converted to Cartesian form in frame {i}\\{i\\} iğjâ™¯=(râ™¯cosÎ²â™¯,râ™¯sinÎ²â™¯)âˆˆâ„2. {^i}\\bm{P}_j^\\sharp = \\left( r^\\sharp\n\\cos{\\beta^\\sharp}, r^\\sharp \\sin{\\beta^\\sharp} \\right) \\in \\mathbb{R}^2. \nThe estimated position of the landmark in frame {i}\\{i\\} is iğÌ‚j=(âŠ–0Î¾i)â€¢ğÌ‚jâˆˆâ„2\n{^i}\\hat{\\bm{P}}_j = \\left( \\ominus {^0}\\xi_i \\right) \\bullet \\hat{\\bm{P}}_j \\in \\mathbb{R}^2  and the error vector is ğŸk(ğ±)=Îµ=iğÌ‚jâˆ’iğjâ™¯âˆˆâ„2. \\bm{f}_k(\\bm{x}) = \\varepsilon = {^i}\\hat{\\bm{P}}_j -\n{^i}\\bm{P}_j^\\sharp \\in \\mathbb{R}^2."
  },
  {
    "objectID": "06_localization.html#complementary-filter-1",
    "href": "06_localization.html#complementary-filter-1",
    "title": "06_localization",
    "section": "Complementary filter",
    "text": "Complementary filter\n\n\n\nThey provide a means to fuse multiple independent noisy measurements of the same signal that have complementary spectral characteristics.\n\nÎ¼1\\mu_1: predominantly high frequency noise\nÎ¼2\\mu_2: predominantly low frequency disturbance\n\nChoose a pair of complementary transfer functions F1(s)+F2(s)=1 F_1(s) + F_2(s) = 1 \n\nF1(s)F_1(s): low-pass transfer function\nF2(s)F_2(s): high-pass transfer function\n\n\n\n\n\n\n\n\n\n\nThe filtered estimate is given by XÌ‚(s)=F1(s)Y1+F2(s)Y2=X(s)+F1(s)Î¼1(s)+F2(s)Î¼2(s). \\hat{X}(s) = F_1(s)Y_1 + F_2(s)Y_2 = X(s) + F_1(s)\\mu_1(s) + F_2(s)\\mu_2(s).\n\nThis type of filter is also known as distorsionless filtering since the signal x(t)x(t) is not distorted by the filter."
  },
  {
    "objectID": "06_localization.html#complementary-filter-2",
    "href": "06_localization.html#complementary-filter-2",
    "title": "06_localization",
    "section": "Complementary filter",
    "text": "Complementary filter\n\nComplementary filters are particularly well suited to fusing low bandwidth position measurements with high band widh rate measurements for first-order kinematic systems xÌ‡=u \\dot{x} = u  with typical measurement characteristics yx=L(s)x+Î¼x,yu=u+Î¼u+b(t) y_x = L(s)x + \\mu_x, \\qquad y_u = u + \\mu_u + b(t) \n\nL(s)L(s): low-pass filter associated with sensor characteristics,\nÎ¼\\mu: noise in both measurements,\nb(t)b(t) is a deterministic perturbation dominated by low-frequency content.\n\nL(s)â‰ˆ1L(s) \\approx 1 over frequency range on which the measurement yxy_x is of interest.\nThe rate measurement is integrated: yus\\frac{y_u}{s} to obtain an estimate of the state and the noise and bias characteristics of the signal are dominantly low frequency effects.\nNow, choose: F1(s)=C(s)C(s)+s,F2(s)=1âˆ’F1(s)=sC(s)+s F_1(s) = \\frac{C(s)}{C(s) + s}, \\qquad F_2(s) = 1 - F_1(s) = \\frac{s}{C(s) +\ns} \n\nC(s)C(s): all pass such that L(s)F1(s)â‰ˆ1L(s)F_1(s) \\approx 1 over the bandwidth of L(s)L(s). Then XÌ‚(s)â‰ˆX(s)+F1(s)Î¼x(s)+Î¼u(s)+b(s)C(s)+s. \\hat{X}(s) \\approx X(s) + F_1(s)\\mu_x(s) + \\frac{\\mu_u(s) + b(s)}{C(s) +\ns}."
  },
  {
    "objectID": "06_localization.html#complementary-filter-3",
    "href": "06_localization.html#complementary-filter-3",
    "title": "06_localization",
    "section": "Complementary filter",
    "text": "Complementary filter\n\n\n\n\nThe filter structure is implemented by exploiting the complementary sensitivity structure of a linear feedback system subject to load disturbance.\n\nxÌ‚(s)=C(s)s+C(s)yx(s)+sC(s)+syu(s)s=T(s)yx(s)+S(s)yu(s)s \\hat{x}(s) = \\frac{C(s)}{s + C(s)} y_x(s) + \\frac{s}{C(s) + s}\n\\frac{y_u(s)}{s} = T(s)y_x(s) + S(s)\\frac{y_u(s)}{s}  where S(s)S(s) is the sensitivity function of the closed-loop system and T(s)T(s) is the complementary sensitivity.\n\nSimplest choice for feedback: C(s)=kpC(s) = k_p. In this case, the CL-dynamics of the filter are given by xÌ‚Ì‡=yu+kp(yxâˆ’xÌ‚). \\dot{\\hat{x}} = y_u + k_p(y_x - \\hat{x}). \nAssociated complementary filters associated with this choice are F1(s)=kps+kp, and F2(s)=ss+kp.F_1(s) = \\frac{k_p}{s+k_p}, \\quad \\text{ and } \\quad  F_2(s) = \\frac{s}{s + k_p}."
  },
  {
    "objectID": "06_localization.html#complementary-filter-4",
    "href": "06_localization.html#complementary-filter-4",
    "title": "06_localization",
    "section": "Complementary filter",
    "text": "Complementary filter\n\nIf the rate measurement bias, b(t)=b0b(t) = b_0, is a constant then it is natural to add an integrator to the compensator to make the system type I C(s)=kp+kis. C(s) = k_p + \\frac{k_i}{s}. \nA type I system will reject the constant load disturbance b0b_0 from the output.\nThe resulting dynamics are xÌ‚Ì‡=yuâˆ’bÌ‚+k(yxâˆ’xÌ‚),bÌ‚Ì‡=âˆ’ki(yxâˆ’xÌ‚). \\dot{\\hat{x}} = y_u - \\hat{b} + k(y_x - \\hat{x}), \\qquad \\dot{\\hat{b}} =\n-k_i(y_x - \\hat{x}). \nConsider the Lyapunov function candidate â„’=12|xâˆ’xÌ‚|2+12ki|b0âˆ’bÌ‚|2. \\mathcal{L} = \\frac{1}{2} \\lvert x - \\hat{x}\\rvert^2 + \\frac{1}{2k_i}\\lvert b_0 - \\hat{b} \\rvert^2. \n\nAbusing the notation for the noise processes and using xÌƒ=xâˆ’xÌ‚\\tilde{x} = x - \\hat{x} and bÌƒ=b0âˆ’bÌ‚\\tilde{b} = b_0 - \\hat{b}, one has ddtâ„’=âˆ’kp|xÌƒ|2âˆ’Î¼uxÌƒ+Î¼x(bÌƒâˆ’kxÌƒ). \\frac{\\text{d}}{\\text{d}t} \\mathcal{L} = -k_p \\lvert \\tilde{x} \\rvert^2 -\n\\mu_u \\tilde{x} + \\mu_x \\left( \\tilde{b} - k \\tilde{x} \\right). \n\nIn the absence of noise, one may apply Lyapunovâ€™s direct method to prove convergence of the state estimate.\n\nLaSalleâ€™s invariance principle may be used to show that bÌ‚â†’b0\\hat{b} \\rightarrow b_0.\nWhen the underlying system is linear, the linear form of the feedback and adaptation law ensure that the CL system is linear and stability implies exponential stability."
  },
  {
    "objectID": "06_localization.html#complementary-filter-on-bmso3",
    "href": "06_localization.html#complementary-filter-on-bmso3",
    "title": "06_localization",
    "section": "Complementary filter on ğ’ğ(3)\\bm{SO}(3)",
    "text": "Complementary filter on ğ’ğ(3)\\bm{SO}(3)\nÂ \n\nEstimation of the roll and pitch angles from IMU using the complementary filter\n\n33-axis linear accelerometer\n33-axis gyro rates\n33-axis magnetometer\n\n\n\n\nÂ \n\n\n\n\n\n\n\n\n\n\n\nRobotics and Automated Systems â€¢ Aykut C. Satici"
  }
]